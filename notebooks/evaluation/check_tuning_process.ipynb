{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we check the scores achieved by our models during the hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from src.common import config, helpers\n",
    "from run import load_hyperparameters\n",
    "\n",
    "pd.options.display.max_rows = 999\n",
    "pd.set_option(\"max_colwidth\", 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = config.Paths(dataset_name=\"jobs_published\", target_users_name=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_model_results(model_name, dir_path):\n",
    "    display(load_hyperparameters(paths.tuning_dir, model_name))\n",
    "    results = helpers.df_from_dir(dir_path).sort_values(by=\"score\", ascending=False)\n",
    "    display(results[results[\"model_name\"] == model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prod2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vector_size': 168,\n",
       " 'alpha': 0.028727691830747873,\n",
       " 'window': 20,\n",
       " 'min_count': 16,\n",
       " 'sample': 0.002690026189508928,\n",
       " 'min_alpha': 0.0,\n",
       " 'sg': 1,\n",
       " 'hs': 1,\n",
       " 'negative': 200,\n",
       " 'ns_exponent': -0.16447846705441527,\n",
       " 'cbow_mean': 0,\n",
       " 'epochs': 22}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>score</th>\n",
       "      <th>model_parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.026743</td>\n",
       "      <td>{\"vector_size\": 168, \"alpha\": 0.028727691830747873, \"window\": 20, \"min_count\": 16, \"sample\": 0.002690026189508928, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": -0.16447846705441527, \"cbow_mean\": 0, \"epochs\": 22}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.026103</td>\n",
       "      <td>{\"vector_size\": 138, \"alpha\": 0.04313491619935656, \"window\": 10, \"min_count\": 15, \"sample\": 0.003431545352139904, \"min_alpha\": 0.0030648901597258465, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": 0.39701588337445193, \"cbow_mean\": 1, \"epochs\": 14}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.026043</td>\n",
       "      <td>{\"vector_size\": 133, \"alpha\": 0.05429137892294831, \"window\": 20, \"min_count\": 8, \"sample\": 0.0017914473886576174, \"min_alpha\": 0.0031460443932356838, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": 0.7829165672916856, \"cbow_mean\": 1, \"epochs\": 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.025590</td>\n",
       "      <td>{\"vector_size\": 132, \"alpha\": 0.04116805977197572, \"window\": 14, \"min_count\": 19, \"sample\": 0.008157671168849571, \"min_alpha\": 0.006717489303064066, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.025473</td>\n",
       "      <td>{\"vector_size\": 135, \"alpha\": 0.01, \"window\": 19, \"min_count\": 20, \"sample\": 0.003782674883618783, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 64, \"ns_exponent\": -0.5, \"cbow_mean\": 0, \"epochs\": 39}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.025460</td>\n",
       "      <td>{\"vector_size\": 99, \"alpha\": 0.05266246879482685, \"window\": 13, \"min_count\": 18, \"sample\": 0.0034870153489873408, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 64, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.025247</td>\n",
       "      <td>{\"vector_size\": 110, \"alpha\": 0.053537764738422214, \"window\": 20, \"min_count\": 20, \"sample\": 0.008552567720786696, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 26, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 14}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.025203</td>\n",
       "      <td>{\"vector_size\": 143, \"alpha\": 0.03943598974543695, \"window\": 20, \"min_count\": 19, \"sample\": 0.0023278025294446608, \"min_alpha\": 0.005482948018275601, \"sg\": 1, \"hs\": 1, \"negative\": 92, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 37}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.024760</td>\n",
       "      <td>{\"vector_size\": 123, \"alpha\": 0.010887007507173446, \"window\": 8, \"min_count\": 4, \"sample\": 0.0032300868025133904, \"min_alpha\": 0.00756971305793599, \"sg\": 1, \"hs\": 1, \"negative\": 190, \"ns_exponent\": 0.7608516213363041, \"cbow_mean\": 0, \"epochs\": 23}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.024643</td>\n",
       "      <td>{\"vector_size\": 163, \"alpha\": 0.01, \"window\": 20, \"min_count\": 10, \"sample\": 0.008880524154262335, \"min_alpha\": 0.004943333448398411, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 18}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.024367</td>\n",
       "      <td>{\"vector_size\": 100, \"alpha\": 0.034789047367445716, \"window\": 20, \"min_count\": 7, \"sample\": 0.009970312188785978, \"min_alpha\": 0.01, \"sg\": 1, \"hs\": 1, \"negative\": 193, \"ns_exponent\": 0.34315208234548955, \"cbow_mean\": 0, \"epochs\": 23}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.024360</td>\n",
       "      <td>{\"vector_size\": 51, \"alpha\": 0.019522783922409193, \"window\": 14, \"min_count\": 15, \"sample\": 0.008596736354419468, \"min_alpha\": 0.00019597913022632028, \"sg\": 1, \"hs\": 1, \"negative\": 52, \"ns_exponent\": -0.38214732172869004, \"cbow_mean\": 1, \"epochs\": 37}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.024350</td>\n",
       "      <td>{\"vector_size\": 91, \"alpha\": 0.05566473261069136, \"window\": 20, \"min_count\": 20, \"sample\": 0.008569133862241314, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 0, \"negative\": 16, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 33}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.024140</td>\n",
       "      <td>{\"vector_size\": 32, \"alpha\": 0.05797940539602309, \"window\": 20, \"min_count\": 5, \"sample\": 0.0001593447647576344, \"min_alpha\": 0.00035793307370459744, \"sg\": 1, \"hs\": 0, \"negative\": 57, \"ns_exponent\": -0.16133464108976098, \"cbow_mean\": 0, \"epochs\": 37}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.024070</td>\n",
       "      <td>{\"vector_size\": 32, \"alpha\": 0.05402373489797004, \"window\": 11, \"min_count\": 19, \"sample\": 0.008095572578952173, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 0, \"negative\": 80, \"ns_exponent\": -0.2792162520850042, \"cbow_mean\": 1, \"epochs\": 36}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.023983</td>\n",
       "      <td>{\"vector_size\": 58, \"alpha\": 0.07503094453882388, \"window\": 10, \"min_count\": 19, \"sample\": 0.001191232125568951, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 0, \"negative\": 77, \"ns_exponent\": -0.0047230845895580575, \"cbow_mean\": 1, \"epochs\": 19}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.023763</td>\n",
       "      <td>{\"vector_size\": 32, \"alpha\": 0.0592128459128618, \"window\": 8, \"min_count\": 20, \"sample\": 0.00621395156480427, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 157, \"ns_exponent\": 0.7467783161922974, \"cbow_mean\": 0, \"epochs\": 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.023677</td>\n",
       "      <td>{\"vector_size\": 32, \"alpha\": 0.05707874099191671, \"window\": 20, \"min_count\": 20, \"sample\": 0.0017640328213924257, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 39}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.023617</td>\n",
       "      <td>{\"vector_size\": 32, \"alpha\": 0.06713281975747316, \"window\": 10, \"min_count\": 20, \"sample\": 0.009147429600951414, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 196, \"ns_exponent\": 0.48322770088098965, \"cbow_mean\": 1, \"epochs\": 27}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.023457</td>\n",
       "      <td>{\"vector_size\": 115, \"alpha\": 0.1015889721487536, \"window\": 8, \"min_count\": 19, \"sample\": 3.6059346565424594e-06, \"min_alpha\": 0.0003022076225879274, \"sg\": 1, \"hs\": 1, \"negative\": 124, \"ns_exponent\": 0.6576155402338049, \"cbow_mean\": 0, \"epochs\": 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>{\"vector_size\": 172, \"alpha\": 0.01, \"window\": 20, \"min_count\": 9, \"sample\": 0.0028995593929572734, \"min_alpha\": 0.0020254675290314714, \"sg\": 1, \"hs\": 1, \"negative\": 1, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 37}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.023273</td>\n",
       "      <td>{\"vector_size\": 32, \"alpha\": 0.05964574435135837, \"window\": 18, \"min_count\": 16, \"sample\": 0.008876134695306612, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 92, \"ns_exponent\": -0.09765205324600112, \"cbow_mean\": 0, \"epochs\": 35}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.023193</td>\n",
       "      <td>{\"vector_size\": 32, \"alpha\": 0.0474664122064446, \"window\": 20, \"min_count\": 20, \"sample\": 0.0004055060114277462, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": -0.5, \"cbow_mean\": 0, \"epochs\": 16}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.023113</td>\n",
       "      <td>{\"vector_size\": 180, \"alpha\": 0.07816659686491069, \"window\": 3, \"min_count\": 17, \"sample\": 0.0021995672391087835, \"min_alpha\": 0.00995155400961014, \"sg\": 1, \"hs\": 1, \"negative\": 1, \"ns_exponent\": 0.6811876909333345, \"cbow_mean\": 0, \"epochs\": 35}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.022663</td>\n",
       "      <td>{\"vector_size\": 114, \"alpha\": 0.045373170055526664, \"window\": 16, \"min_count\": 11, \"sample\": 0.005130252073538585, \"min_alpha\": 0.002673278398009932, \"sg\": 1, \"hs\": 0, \"negative\": 78, \"ns_exponent\": -0.42970032269339087, \"cbow_mean\": 0, \"epochs\": 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.022353</td>\n",
       "      <td>{\"vector_size\": 35, \"alpha\": 0.0872668924916005, \"window\": 3, \"min_count\": 7, \"sample\": 0.001987996448905776, \"min_alpha\": 0.0010214921011748672, \"sg\": 1, \"hs\": 1, \"negative\": 194, \"ns_exponent\": 0.7718502734409334, \"cbow_mean\": 1, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.021983</td>\n",
       "      <td>{\"vector_size\": 32, \"alpha\": 0.07005874796139837, \"window\": 20, \"min_count\": 20, \"sample\": 0.0003311200732357621, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 32, \"ns_exponent\": 0.5332718088026134, \"cbow_mean\": 1, \"epochs\": 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.021867</td>\n",
       "      <td>{\"vector_size\": 32, \"alpha\": 0.03296252874183587, \"window\": 20, \"min_count\": 20, \"sample\": 0.007393817307345747, \"min_alpha\": 0.005249290049631279, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": 0.4095251313053274, \"cbow_mean\": 1, \"epochs\": 38}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.021823</td>\n",
       "      <td>{\"vector_size\": 51, \"alpha\": 0.11963179123406989, \"window\": 13, \"min_count\": 18, \"sample\": 0.009623849435582253, \"min_alpha\": 0.006799187345371015, \"sg\": 1, \"hs\": 1, \"negative\": 48, \"ns_exponent\": 1.4219775036375866, \"cbow_mean\": 1, \"epochs\": 13}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.021607</td>\n",
       "      <td>{\"vector_size\": 32, \"alpha\": 0.053289420357238854, \"window\": 20, \"min_count\": 20, \"sample\": 0.0, \"min_alpha\": 0.00484474251658218, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": -0.5, \"cbow_mean\": 0, \"epochs\": 17}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.021580</td>\n",
       "      <td>{\"vector_size\": 32, \"alpha\": 0.0480851457233036, \"window\": 17, \"min_count\": 14, \"sample\": 0.002186861353368606, \"min_alpha\": 0.007019512688849859, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": 1.1322950878847287, \"cbow_mean\": 0, \"epochs\": 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.020950</td>\n",
       "      <td>{\"vector_size\": 72, \"alpha\": 0.09650448934046392, \"window\": 2, \"min_count\": 19, \"sample\": 0.005057896428504944, \"min_alpha\": 0.009255123151381757, \"sg\": 0, \"hs\": 1, \"negative\": 38, \"ns_exponent\": -0.4645316224117231, \"cbow_mean\": 1, \"epochs\": 21}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.020943</td>\n",
       "      <td>{\"vector_size\": 85, \"alpha\": 0.04449712042762617, \"window\": 20, \"min_count\": 1, \"sample\": 0.0, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 13}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.020333</td>\n",
       "      <td>{\"vector_size\": 504, \"alpha\": 0.015520861060438186, \"window\": 20, \"min_count\": 20, \"sample\": 0.00778376984373306, \"min_alpha\": 0.001997015119017354, \"sg\": 1, \"hs\": 1, \"negative\": 147, \"ns_exponent\": 1.4087472665471947, \"cbow_mean\": 1, \"epochs\": 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.018930</td>\n",
       "      <td>{\"vector_size\": 32, \"alpha\": 0.07003652844830963, \"window\": 8, \"min_count\": 5, \"sample\": 0.008340867774243746, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 1, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.018857</td>\n",
       "      <td>{\"vector_size\": 512, \"alpha\": 0.01, \"window\": 20, \"min_count\": 10, \"sample\": 0.0013313031880266232, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 165, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 34}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.018687</td>\n",
       "      <td>{\"vector_size\": 32, \"alpha\": 0.01, \"window\": 20, \"min_count\": 9, \"sample\": 0.007925337107496691, \"min_alpha\": 0.005668805235168937, \"sg\": 1, \"hs\": 1, \"negative\": 8, \"ns_exponent\": -0.5, \"cbow_mean\": 0, \"epochs\": 33}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.018497</td>\n",
       "      <td>{\"vector_size\": 477, \"alpha\": 0.020771681778074966, \"window\": 11, \"min_count\": 9, \"sample\": 0.0012068933106558091, \"min_alpha\": 0.0001430591941553783, \"sg\": 1, \"hs\": 1, \"negative\": 24, \"ns_exponent\": 0.0032201764725420245, \"cbow_mean\": 0, \"epochs\": 23}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.018343</td>\n",
       "      <td>{\"vector_size\": 168, \"alpha\": 0.01, \"window\": 1, \"min_count\": 6, \"sample\": 0.00573955047897152, \"min_alpha\": 0.01, \"sg\": 1, \"hs\": 1, \"negative\": 1, \"ns_exponent\": 1.5, \"cbow_mean\": 1, \"epochs\": 21}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.018267</td>\n",
       "      <td>{\"vector_size\": 32, \"alpha\": 0.105968801398386, \"window\": 17, \"min_count\": 20, \"sample\": 0.00355566201855149, \"min_alpha\": 0.007633278704116434, \"sg\": 1, \"hs\": 1, \"negative\": 20, \"ns_exponent\": 0.1905807522431322, \"cbow_mean\": 0, \"epochs\": 37}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.017853</td>\n",
       "      <td>{\"vector_size\": 306, \"alpha\": 0.06147667483695896, \"window\": 10, \"min_count\": 20, \"sample\": 0.003927505628049303, \"min_alpha\": 0.007522263025511343, \"sg\": 0, \"hs\": 0, \"negative\": 55, \"ns_exponent\": 0.026826698483518263, \"cbow_mean\": 1, \"epochs\": 27}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.017603</td>\n",
       "      <td>{\"vector_size\": 247, \"alpha\": 0.15721826024066973, \"window\": 19, \"min_count\": 20, \"sample\": 0.007150874316991576, \"min_alpha\": 0.004374968220954116, \"sg\": 0, \"hs\": 0, \"negative\": 19, \"ns_exponent\": 1.4829970741937542, \"cbow_mean\": 1, \"epochs\": 33}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.017387</td>\n",
       "      <td>{\"vector_size\": 32, \"alpha\": 0.01, \"window\": 20, \"min_count\": 20, \"sample\": 0.0, \"min_alpha\": 0.0053524322356035, \"sg\": 1, \"hs\": 1, \"negative\": 1, \"ns_exponent\": 0.7308747412887151, \"cbow_mean\": 1, \"epochs\": 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.017233</td>\n",
       "      <td>{\"vector_size\": 32, \"alpha\": 0.01, \"window\": 1, \"min_count\": 18, \"sample\": 0.0067685302199028555, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 1, \"ns_exponent\": -0.12062004630240025, \"cbow_mean\": 1, \"epochs\": 9}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.016950</td>\n",
       "      <td>{\"vector_size\": 32, \"alpha\": 0.01, \"window\": 2, \"min_count\": 8, \"sample\": 0.004975520058055087, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 169, \"ns_exponent\": 1.0636377522530895, \"cbow_mean\": 0, \"epochs\": 22}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.016847</td>\n",
       "      <td>{\"vector_size\": 346, \"alpha\": 0.08533824204282285, \"window\": 19, \"min_count\": 16, \"sample\": 0.0032412756663735606, \"min_alpha\": 0.00018735795849837426, \"sg\": 1, \"hs\": 1, \"negative\": 4, \"ns_exponent\": 1.4947454752362213, \"cbow_mean\": 0, \"epochs\": 39}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>{\"vector_size\": 488, \"alpha\": 0.07978395359109582, \"window\": 12, \"min_count\": 20, \"sample\": 0.0036862826710160734, \"min_alpha\": 0.005246774938026982, \"sg\": 1, \"hs\": 0, \"negative\": 21, \"ns_exponent\": -0.006832345614956381, \"cbow_mean\": 1, \"epochs\": 23}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.016690</td>\n",
       "      <td>{\"vector_size\": 110, \"alpha\": 0.050423676828064694, \"window\": 20, \"min_count\": 19, \"sample\": 0.008123428665266557, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 0, \"negative\": 200, \"ns_exponent\": -0.5, \"cbow_mean\": 0, \"epochs\": 34}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.016327</td>\n",
       "      <td>{\"vector_size\": 334, \"alpha\": 0.015520702321516127, \"window\": 17, \"min_count\": 19, \"sample\": 0.001199561847985863, \"min_alpha\": 0.008349294986079586, \"sg\": 1, \"hs\": 1, \"negative\": 3, \"ns_exponent\": 1.4272009721187031, \"cbow_mean\": 1, \"epochs\": 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.016060</td>\n",
       "      <td>{\"vector_size\": 94, \"alpha\": 0.06947270236917544, \"window\": 1, \"min_count\": 17, \"sample\": 0.0002136961736272643, \"min_alpha\": 0.01, \"sg\": 1, \"hs\": 1, \"negative\": 167, \"ns_exponent\": 1.5, \"cbow_mean\": 1, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.015953</td>\n",
       "      <td>{\"vector_size\": 84, \"alpha\": 0.012598763642146597, \"window\": 15, \"min_count\": 1, \"sample\": 0.005332893476479776, \"min_alpha\": 0.0021431676191946496, \"sg\": 1, \"hs\": 1, \"negative\": 71, \"ns_exponent\": 1.4876674649477886, \"cbow_mean\": 1, \"epochs\": 13}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.015050</td>\n",
       "      <td>{\"vector_size\": 219, \"alpha\": 0.010532155940595088, \"window\": 20, \"min_count\": 17, \"sample\": 0.002596885666587699, \"min_alpha\": 0.007035468385230185, \"sg\": 0, \"hs\": 1, \"negative\": 52, \"ns_exponent\": 0.002409712203672254, \"cbow_mean\": 1, \"epochs\": 6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.014420</td>\n",
       "      <td>{\"vector_size\": 69, \"alpha\": 0.01019818022715307, \"window\": 6, \"min_count\": 20, \"sample\": 0.004502991639412014, \"min_alpha\": 0.00480787924893628, \"sg\": 1, \"hs\": 0, \"negative\": 144, \"ns_exponent\": 0.4413687399264423, \"cbow_mean\": 0, \"epochs\": 24}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.014053</td>\n",
       "      <td>{\"vector_size\": 286, \"alpha\": 0.14295874537849584, \"window\": 11, \"min_count\": 17, \"sample\": 0.003687185472403522, \"min_alpha\": 0.008709956417240641, \"sg\": 0, \"hs\": 0, \"negative\": 8, \"ns_exponent\": -0.46001165624864754, \"cbow_mean\": 1, \"epochs\": 21}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.013293</td>\n",
       "      <td>{\"vector_size\": 485, \"alpha\": 0.12049588890181084, \"window\": 5, \"min_count\": 18, \"sample\": 0.0014053117205029167, \"min_alpha\": 0.0036341585673360906, \"sg\": 0, \"hs\": 0, \"negative\": 123, \"ns_exponent\": -0.05898583722673212, \"cbow_mean\": 1, \"epochs\": 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.013293</td>\n",
       "      <td>{\"vector_size\": 81, \"alpha\": 0.10085489690278043, \"window\": 2, \"min_count\": 20, \"sample\": 0.008923419484562661, \"min_alpha\": 0.009385140728705138, \"sg\": 0, \"hs\": 1, \"negative\": 79, \"ns_exponent\": 1.1931504773134571, \"cbow_mean\": 1, \"epochs\": 28}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.013130</td>\n",
       "      <td>{\"vector_size\": 32, \"alpha\": 0.06396030196382446, \"window\": 3, \"min_count\": 18, \"sample\": 0.004364170938095114, \"min_alpha\": 0.008907990434193486, \"sg\": 1, \"hs\": 0, \"negative\": 136, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.012133</td>\n",
       "      <td>{\"vector_size\": 512, \"alpha\": 0.10463926379679948, \"window\": 18, \"min_count\": 14, \"sample\": 0.005000081960071909, \"min_alpha\": 0.0030152634762777115, \"sg\": 1, \"hs\": 1, \"negative\": 91, \"ns_exponent\": -0.48682123012667966, \"cbow_mean\": 1, \"epochs\": 18}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.012110</td>\n",
       "      <td>{\"vector_size\": 101, \"alpha\": 0.05464686732188873, \"window\": 20, \"min_count\": 18, \"sample\": 0.0001696930997441109, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 0, \"negative\": 200, \"ns_exponent\": 1.4094618736021645, \"cbow_mean\": 1, \"epochs\": 28}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.012037</td>\n",
       "      <td>{\"vector_size\": 297, \"alpha\": 0.09082082551852323, \"window\": 8, \"min_count\": 4, \"sample\": 0.005696184059233068, \"min_alpha\": 0.007037372792899164, \"sg\": 0, \"hs\": 0, \"negative\": 151, \"ns_exponent\": 0.2921965508467248, \"cbow_mean\": 1, \"epochs\": 27}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.011803</td>\n",
       "      <td>{\"vector_size\": 224, \"alpha\": 0.01, \"window\": 1, \"min_count\": 20, \"sample\": 0.005601902299240549, \"min_alpha\": 0.01, \"sg\": 0, \"hs\": 1, \"negative\": 28, \"ns_exponent\": -0.5, \"cbow_mean\": 0, \"epochs\": 37}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>{\"vector_size\": 32, \"alpha\": 0.01, \"window\": 9, \"min_count\": 12, \"sample\": 0.0006659733641450339, \"min_alpha\": 0.01, \"sg\": 1, \"hs\": 0, \"negative\": 200, \"ns_exponent\": 0.7879738877270659, \"cbow_mean\": 0, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.011193</td>\n",
       "      <td>{\"vector_size\": 511, \"alpha\": 0.16839306146958033, \"window\": 19, \"min_count\": 20, \"sample\": 0.009149999666668995, \"min_alpha\": 0.008135071910738, \"sg\": 0, \"hs\": 0, \"negative\": 18, \"ns_exponent\": -0.2943499232472799, \"cbow_mean\": 0, \"epochs\": 23}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.010883</td>\n",
       "      <td>{\"vector_size\": 154, \"alpha\": 0.06336151461857757, \"window\": 16, \"min_count\": 18, \"sample\": 0.0, \"min_alpha\": 0.005447823572048148, \"sg\": 0, \"hs\": 1, \"negative\": 28, \"ns_exponent\": 1.1618514164550806, \"cbow_mean\": 0, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.010223</td>\n",
       "      <td>{\"vector_size\": 466, \"alpha\": 0.02561243587791314, \"window\": 8, \"min_count\": 19, \"sample\": 0.00015373822710633447, \"min_alpha\": 0.00014660082156420603, \"sg\": 1, \"hs\": 0, \"negative\": 6, \"ns_exponent\": 0.3007970430992072, \"cbow_mean\": 1, \"epochs\": 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.009903</td>\n",
       "      <td>{\"vector_size\": 290, \"alpha\": 0.02367203087676724, \"window\": 5, \"min_count\": 2, \"sample\": 0.00043974041818537125, \"min_alpha\": 0.00980664394588597, \"sg\": 1, \"hs\": 1, \"negative\": 153, \"ns_exponent\": 0.22860986454186105, \"cbow_mean\": 0, \"epochs\": 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.009890</td>\n",
       "      <td>{\"vector_size\": 41, \"alpha\": 0.011490523704024595, \"window\": 5, \"min_count\": 12, \"sample\": 0.0007556188235372032, \"min_alpha\": 0.006382821443245606, \"sg\": 0, \"hs\": 0, \"negative\": 7, \"ns_exponent\": -0.436239363736715, \"cbow_mean\": 1, \"epochs\": 7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.009877</td>\n",
       "      <td>{\"vector_size\": 387, \"alpha\": 0.042331695359167955, \"window\": 15, \"min_count\": 20, \"sample\": 0.003325514745769446, \"min_alpha\": 0.002437153954900149, \"sg\": 1, \"hs\": 0, \"negative\": 1, \"ns_exponent\": 0.42059012366757476, \"cbow_mean\": 1, \"epochs\": 16}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.009803</td>\n",
       "      <td>{\"vector_size\": 32, \"alpha\": 0.01, \"window\": 5, \"min_count\": 17, \"sample\": 0.006890079946580023, \"min_alpha\": 0.009720077650809908, \"sg\": 1, \"hs\": 0, \"negative\": 1, \"ns_exponent\": -0.29376940761134973, \"cbow_mean\": 1, \"epochs\": 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.008460</td>\n",
       "      <td>{\"vector_size\": 512, \"alpha\": 0.01, \"window\": 1, \"min_count\": 20, \"sample\": 0.005959587789397423, \"min_alpha\": 0.01, \"sg\": 1, \"hs\": 0, \"negative\": 200, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 21}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.007713</td>\n",
       "      <td>{\"vector_size\": 495, \"alpha\": 0.0189264861206375, \"window\": 10, \"min_count\": 10, \"sample\": 0.006556153027161558, \"min_alpha\": 0.002600686794933334, \"sg\": 0, \"hs\": 1, \"negative\": 49, \"ns_exponent\": 0.11132447133617196, \"cbow_mean\": 0, \"epochs\": 33}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.006577</td>\n",
       "      <td>{\"vector_size\": 95, \"alpha\": 0.03175134619622058, \"window\": 14, \"min_count\": 8, \"sample\": 0.004458775530438851, \"min_alpha\": 0.0005646144847740984, \"sg\": 0, \"hs\": 0, \"negative\": 133, \"ns_exponent\": -0.44683445677283323, \"cbow_mean\": 0, \"epochs\": 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.005953</td>\n",
       "      <td>{\"vector_size\": 478, \"alpha\": 0.019651823643549608, \"window\": 2, \"min_count\": 15, \"sample\": 0.00689764288350841, \"min_alpha\": 0.008368164152911388, \"sg\": 0, \"hs\": 0, \"negative\": 40, \"ns_exponent\": 1.2630911248973271, \"cbow_mean\": 0, \"epochs\": 35}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>{\"vector_size\": 56, \"alpha\": 0.1589967917140891, \"window\": 1, \"min_count\": 20, \"sample\": 0.004232113306278263, \"min_alpha\": 0.008365324155197177, \"sg\": 1, \"hs\": 0, \"negative\": 59, \"ns_exponent\": 0.5999024378800428, \"cbow_mean\": 1, \"epochs\": 39}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.004453</td>\n",
       "      <td>{\"vector_size\": 34, \"alpha\": 0.012719917840200268, \"window\": 7, \"min_count\": 19, \"sample\": 0.009497752742463693, \"min_alpha\": 0.001366708434511347, \"sg\": 0, \"hs\": 0, \"negative\": 161, \"ns_exponent\": 0.6351815658775408, \"cbow_mean\": 0, \"epochs\": 37}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>{\"vector_size\": 512, \"alpha\": 0.20713706002361992, \"window\": 19, \"min_count\": 11, \"sample\": 0.001436781332807328, \"min_alpha\": 0.0003810483617761696, \"sg\": 1, \"hs\": 0, \"negative\": 127, \"ns_exponent\": 0.10294654184641983, \"cbow_mean\": 0, \"epochs\": 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>{\"vector_size\": 324, \"alpha\": 0.16927314221409276, \"window\": 2, \"min_count\": 13, \"sample\": 0.009589492686245206, \"min_alpha\": 0.006527903170054909, \"sg\": 1, \"hs\": 1, \"negative\": 117, \"ns_exponent\": 0.3287371764527378, \"cbow_mean\": 0, \"epochs\": 27}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>{\"vector_size\": 95, \"alpha\": 0.12792192564599866, \"window\": 14, \"min_count\": 19, \"sample\": 0.004519611550970182, \"min_alpha\": 3.7698902602270056e-05, \"sg\": 0, \"hs\": 1, \"negative\": 56, \"ns_exponent\": -0.34366781025479254, \"cbow_mean\": 0, \"epochs\": 34}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>{\"vector_size\": 32, \"alpha\": 0.08242618134967342, \"window\": 11, \"min_count\": 2, \"sample\": 0.003638856047086074, \"min_alpha\": 0.009263806843660108, \"sg\": 0, \"hs\": 1, \"negative\": 198, \"ns_exponent\": -0.4261338108513455, \"cbow_mean\": 0, \"epochs\": 6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>{\"vector_size\": 292, \"alpha\": 0.46170756556905423, \"window\": 5, \"min_count\": 8, \"sample\": 0.0002703782169606418, \"min_alpha\": 0.009999089673847553, \"sg\": 1, \"hs\": 0, \"negative\": 7, \"ns_exponent\": 1.044038030841851, \"cbow_mean\": 1, \"epochs\": 39}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>{\"vector_size\": 317, \"alpha\": 0.4236902168046986, \"window\": 17, \"min_count\": 17, \"sample\": 0.006235636967859725, \"min_alpha\": 0.0038438170729269993, \"sg\": 0, \"hs\": 0, \"negative\": 55, \"ns_exponent\": 0.45533023464269995, \"cbow_mean\": 1, \"epochs\": 22}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>{\"vector_size\": 193, \"alpha\": 0.06334327011492613, \"window\": 1, \"min_count\": 1, \"sample\": 0.0014004799353865209, \"min_alpha\": 0.01, \"sg\": 1, \"hs\": 0, \"negative\": 1, \"ns_exponent\": 1.313341870837467, \"cbow_mean\": 0, \"epochs\": 29}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>{\"vector_size\": 512, \"alpha\": 0.01, \"window\": 19, \"min_count\": 1, \"sample\": 0.00522451979904354, \"min_alpha\": 0.01, \"sg\": 1, \"hs\": 0, \"negative\": 113, \"ns_exponent\": 1.5, \"cbow_mean\": 1, \"epochs\": 26}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>{\"vector_size\": 57, \"alpha\": 0.18647605732198, \"window\": 7, \"min_count\": 2, \"sample\": 0.006174535865558141, \"min_alpha\": 0.0004709690075481433, \"sg\": 1, \"hs\": 0, \"negative\": 170, \"ns_exponent\": -0.4619606993180334, \"cbow_mean\": 0, \"epochs\": 38}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>{\"vector_size\": 419, \"alpha\": 0.4907507168868534, \"window\": 1, \"min_count\": 6, \"sample\": 0.006581227344786839, \"min_alpha\": 0.0011467590278891517, \"sg\": 0, \"hs\": 0, \"negative\": 73, \"ns_exponent\": -0.4410081695468102, \"cbow_mean\": 0, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>{\"vector_size\": 321, \"alpha\": 0.25970303807785283, \"window\": 15, \"min_count\": 1, \"sample\": 0.0014462423092202472, \"min_alpha\": 0.005766934487021346, \"sg\": 1, \"hs\": 1, \"negative\": 4, \"ns_exponent\": 0.35034395292792997, \"cbow_mean\": 0, \"epochs\": 6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>{\"vector_size\": 460, \"alpha\": 0.3432272290370721, \"window\": 10, \"min_count\": 20, \"sample\": 0.0011620190961239443, \"min_alpha\": 0.00767023703558727, \"sg\": 0, \"hs\": 1, \"negative\": 51, \"ns_exponent\": 0.126436663891902, \"cbow_mean\": 1, \"epochs\": 26}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>{\"vector_size\": 38, \"alpha\": 0.4888402826846181, \"window\": 11, \"min_count\": 2, \"sample\": 0.006552129382665774, \"min_alpha\": 0.0001860573563738688, \"sg\": 0, \"hs\": 0, \"negative\": 113, \"ns_exponent\": -0.025880124487907996, \"cbow_mean\": 1, \"epochs\": 34}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>{\"vector_size\": 38, \"alpha\": 0.30080127542618607, \"window\": 20, \"min_count\": 4, \"sample\": 0.0013893804388576583, \"min_alpha\": 0.005984067181448116, \"sg\": 0, \"hs\": 0, \"negative\": 157, \"ns_exponent\": -0.4556266115057819, \"cbow_mean\": 1, \"epochs\": 29}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>{\"vector_size\": 504, \"alpha\": 0.5, \"window\": 5, \"min_count\": 1, \"sample\": 0.009992306440154147, \"min_alpha\": 0.007124425193490977, \"sg\": 0, \"hs\": 0, \"negative\": 200, \"ns_exponent\": 1.0727015353089016, \"cbow_mean\": 1, \"epochs\": 6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>{\"vector_size\": 37, \"alpha\": 0.3632297916313799, \"window\": 20, \"min_count\": 19, \"sample\": 0.009648740656265226, \"min_alpha\": 0.00794328012630056, \"sg\": 1, \"hs\": 0, \"negative\": 118, \"ns_exponent\": 1.2123906052541904, \"cbow_mean\": 1, \"epochs\": 34}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>{\"vector_size\": 494, \"alpha\": 0.49959985706773874, \"window\": 14, \"min_count\": 19, \"sample\": 0.005034269304000619, \"min_alpha\": 0.0037266615183304645, \"sg\": 1, \"hs\": 1, \"negative\": 26, \"ns_exponent\": 1.2031417823782617, \"cbow_mean\": 0, \"epochs\": 37}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>{\"vector_size\": 447, \"alpha\": 0.25939479072683713, \"window\": 18, \"min_count\": 19, \"sample\": 0.000831124926306024, \"min_alpha\": 0.002777185612810325, \"sg\": 0, \"hs\": 1, \"negative\": 130, \"ns_exponent\": 1.1827722383947092, \"cbow_mean\": 0, \"epochs\": 19}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>{\"vector_size\": 194, \"alpha\": 0.3406286379069202, \"window\": 7, \"min_count\": 16, \"sample\": 0.009495710534507424, \"min_alpha\": 0.006625268669500444, \"sg\": 0, \"hs\": 1, \"negative\": 135, \"ns_exponent\": 1.443890004999332, \"cbow_mean\": 1, \"epochs\": 23}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>{\"vector_size\": 139, \"alpha\": 0.1993796007516724, \"window\": 18, \"min_count\": 10, \"sample\": 0.006130634578841325, \"min_alpha\": 0.009023485831739845, \"sg\": 0, \"hs\": 1, \"negative\": 131, \"ns_exponent\": -0.15818082972790964, \"cbow_mean\": 0, \"epochs\": 31}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>{\"vector_size\": 59, \"alpha\": 0.23106801511525482, \"window\": 1, \"min_count\": 9, \"sample\": 0.009795867288127287, \"min_alpha\": 0.0035944446396932155, \"sg\": 0, \"hs\": 1, \"negative\": 176, \"ns_exponent\": 1.3364709327242899, \"cbow_mean\": 0, \"epochs\": 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>{\"vector_size\": 50, \"alpha\": 0.5, \"window\": 8, \"min_count\": 15, \"sample\": 0.00041411145488896666, \"min_alpha\": 0.0011546154951504507, \"sg\": 1, \"hs\": 1, \"negative\": 84, \"ns_exponent\": -0.2898992160137226, \"cbow_mean\": 1, \"epochs\": 17}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>{\"vector_size\": 378, \"alpha\": 0.29518969811680257, \"window\": 11, \"min_count\": 15, \"sample\": 0.0010590760718779215, \"min_alpha\": 0.0047360041934665755, \"sg\": 0, \"hs\": 1, \"negative\": 44, \"ns_exponent\": -0.22956365318909583, \"cbow_mean\": 0, \"epochs\": 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>{\"vector_size\": 221, \"alpha\": 0.4196785941333151, \"window\": 7, \"min_count\": 13, \"sample\": 0.00368241539840548, \"min_alpha\": 0.009571551589530465, \"sg\": 0, \"hs\": 1, \"negative\": 95, \"ns_exponent\": 1.101821503959289, \"cbow_mean\": 1, \"epochs\": 29}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>prod2vec</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>{\"vector_size\": 241, \"alpha\": 0.357124731406364, \"window\": 16, \"min_count\": 2, \"sample\": 0.007067355100237635, \"min_alpha\": 0.0001671380508565679, \"sg\": 1, \"hs\": 1, \"negative\": 119, \"ns_exponent\": -0.16720859807727279, \"cbow_mean\": 0, \"epochs\": 9}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name     score  \\\n",
       "36    prod2vec  0.026743   \n",
       "8     prod2vec  0.026103   \n",
       "37    prod2vec  0.026043   \n",
       "14    prod2vec  0.025590   \n",
       "280   prod2vec  0.025473   \n",
       "152   prod2vec  0.025460   \n",
       "399   prod2vec  0.025247   \n",
       "212   prod2vec  0.025203   \n",
       "195   prod2vec  0.024760   \n",
       "362   prod2vec  0.024643   \n",
       "161   prod2vec  0.024367   \n",
       "393   prod2vec  0.024360   \n",
       "53    prod2vec  0.024350   \n",
       "326   prod2vec  0.024140   \n",
       "211   prod2vec  0.024070   \n",
       "247   prod2vec  0.023983   \n",
       "158   prod2vec  0.023763   \n",
       "237   prod2vec  0.023677   \n",
       "381   prod2vec  0.023617   \n",
       "265   prod2vec  0.023457   \n",
       "116   prod2vec  0.023400   \n",
       "85    prod2vec  0.023273   \n",
       "229   prod2vec  0.023193   \n",
       "135   prod2vec  0.023113   \n",
       "352   prod2vec  0.022663   \n",
       "285   prod2vec  0.022353   \n",
       "272   prod2vec  0.021983   \n",
       "348   prod2vec  0.021867   \n",
       "277   prod2vec  0.021823   \n",
       "181   prod2vec  0.021607   \n",
       "214   prod2vec  0.021580   \n",
       "95    prod2vec  0.020950   \n",
       "115   prod2vec  0.020943   \n",
       "79    prod2vec  0.020333   \n",
       "246   prod2vec  0.018930   \n",
       "117   prod2vec  0.018857   \n",
       "175   prod2vec  0.018687   \n",
       "113   prod2vec  0.018497   \n",
       "50    prod2vec  0.018343   \n",
       "351   prod2vec  0.018267   \n",
       "311   prod2vec  0.017853   \n",
       "87    prod2vec  0.017603   \n",
       "374   prod2vec  0.017387   \n",
       "38    prod2vec  0.017233   \n",
       "314   prod2vec  0.016950   \n",
       "234   prod2vec  0.016847   \n",
       "384   prod2vec  0.016760   \n",
       "304   prod2vec  0.016690   \n",
       "392   prod2vec  0.016327   \n",
       "361   prod2vec  0.016060   \n",
       "213   prod2vec  0.015953   \n",
       "322   prod2vec  0.015050   \n",
       "382   prod2vec  0.014420   \n",
       "130   prod2vec  0.014053   \n",
       "254   prod2vec  0.013293   \n",
       "216   prod2vec  0.013293   \n",
       "289   prod2vec  0.013130   \n",
       "202   prod2vec  0.012133   \n",
       "182   prod2vec  0.012110   \n",
       "155   prod2vec  0.012037   \n",
       "102   prod2vec  0.011803   \n",
       "365   prod2vec  0.011783   \n",
       "104   prod2vec  0.011193   \n",
       "363   prod2vec  0.010883   \n",
       "252   prod2vec  0.010223   \n",
       "260   prod2vec  0.009903   \n",
       "150   prod2vec  0.009890   \n",
       "80    prod2vec  0.009877   \n",
       "251   prod2vec  0.009803   \n",
       "159   prod2vec  0.008460   \n",
       "332   prod2vec  0.007713   \n",
       "142   prod2vec  0.006577   \n",
       "149   prod2vec  0.005953   \n",
       "59    prod2vec  0.005713   \n",
       "120   prod2vec  0.004453   \n",
       "128   prod2vec  0.003213   \n",
       "298   prod2vec  0.003053   \n",
       "388   prod2vec  0.002877   \n",
       "75    prod2vec  0.002253   \n",
       "176   prod2vec  0.001890   \n",
       "1     prod2vec  0.001850   \n",
       "180   prod2vec  0.001777   \n",
       "15    prod2vec  0.001517   \n",
       "369   prod2vec  0.001453   \n",
       "224   prod2vec  0.000813   \n",
       "389   prod2vec  0.000800   \n",
       "194   prod2vec  0.000577   \n",
       "218   prod2vec  0.000360   \n",
       "73    prod2vec  0.000340   \n",
       "52    prod2vec  0.000227   \n",
       "222   prod2vec  0.000223   \n",
       "140   prod2vec  0.000210   \n",
       "16    prod2vec  0.000193   \n",
       "244   prod2vec  0.000163   \n",
       "168   prod2vec  0.000157   \n",
       "263   prod2vec  0.000153   \n",
       "49    prod2vec  0.000147   \n",
       "279   prod2vec  0.000143   \n",
       "364   prod2vec  0.000137   \n",
       "43    prod2vec  0.000110   \n",
       "\n",
       "                                                                                                                                                                                                                                                 model_parameters  \n",
       "36                     {\"vector_size\": 168, \"alpha\": 0.028727691830747873, \"window\": 20, \"min_count\": 16, \"sample\": 0.002690026189508928, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": -0.16447846705441527, \"cbow_mean\": 0, \"epochs\": 22}  \n",
       "8      {\"vector_size\": 138, \"alpha\": 0.04313491619935656, \"window\": 10, \"min_count\": 15, \"sample\": 0.003431545352139904, \"min_alpha\": 0.0030648901597258465, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": 0.39701588337445193, \"cbow_mean\": 1, \"epochs\": 14}  \n",
       "37      {\"vector_size\": 133, \"alpha\": 0.05429137892294831, \"window\": 20, \"min_count\": 8, \"sample\": 0.0017914473886576174, \"min_alpha\": 0.0031460443932356838, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": 0.7829165672916856, \"cbow_mean\": 1, \"epochs\": 10}  \n",
       "14                     {\"vector_size\": 132, \"alpha\": 0.04116805977197572, \"window\": 14, \"min_count\": 19, \"sample\": 0.008157671168849571, \"min_alpha\": 0.006717489303064066, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 12}  \n",
       "280                                                     {\"vector_size\": 135, \"alpha\": 0.01, \"window\": 19, \"min_count\": 20, \"sample\": 0.003782674883618783, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 64, \"ns_exponent\": -0.5, \"cbow_mean\": 0, \"epochs\": 39}  \n",
       "152                                      {\"vector_size\": 99, \"alpha\": 0.05266246879482685, \"window\": 13, \"min_count\": 18, \"sample\": 0.0034870153489873408, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 64, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 15}  \n",
       "399                                     {\"vector_size\": 110, \"alpha\": 0.053537764738422214, \"window\": 20, \"min_count\": 20, \"sample\": 0.008552567720786696, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 26, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 14}  \n",
       "212                    {\"vector_size\": 143, \"alpha\": 0.03943598974543695, \"window\": 20, \"min_count\": 19, \"sample\": 0.0023278025294446608, \"min_alpha\": 0.005482948018275601, \"sg\": 1, \"hs\": 1, \"negative\": 92, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 37}  \n",
       "195       {\"vector_size\": 123, \"alpha\": 0.010887007507173446, \"window\": 8, \"min_count\": 4, \"sample\": 0.0032300868025133904, \"min_alpha\": 0.00756971305793599, \"sg\": 1, \"hs\": 1, \"negative\": 190, \"ns_exponent\": 0.7608516213363041, \"cbow_mean\": 0, \"epochs\": 23}  \n",
       "362                                   {\"vector_size\": 163, \"alpha\": 0.01, \"window\": 20, \"min_count\": 10, \"sample\": 0.008880524154262335, \"min_alpha\": 0.004943333448398411, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 18}  \n",
       "161                     {\"vector_size\": 100, \"alpha\": 0.034789047367445716, \"window\": 20, \"min_count\": 7, \"sample\": 0.009970312188785978, \"min_alpha\": 0.01, \"sg\": 1, \"hs\": 1, \"negative\": 193, \"ns_exponent\": 0.34315208234548955, \"cbow_mean\": 0, \"epochs\": 23}  \n",
       "393   {\"vector_size\": 51, \"alpha\": 0.019522783922409193, \"window\": 14, \"min_count\": 15, \"sample\": 0.008596736354419468, \"min_alpha\": 0.00019597913022632028, \"sg\": 1, \"hs\": 1, \"negative\": 52, \"ns_exponent\": -0.38214732172869004, \"cbow_mean\": 1, \"epochs\": 37}  \n",
       "53                                        {\"vector_size\": 91, \"alpha\": 0.05566473261069136, \"window\": 20, \"min_count\": 20, \"sample\": 0.008569133862241314, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 0, \"negative\": 16, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 33}  \n",
       "326    {\"vector_size\": 32, \"alpha\": 0.05797940539602309, \"window\": 20, \"min_count\": 5, \"sample\": 0.0001593447647576344, \"min_alpha\": 0.00035793307370459744, \"sg\": 1, \"hs\": 0, \"negative\": 57, \"ns_exponent\": -0.16133464108976098, \"cbow_mean\": 0, \"epochs\": 37}  \n",
       "211                        {\"vector_size\": 32, \"alpha\": 0.05402373489797004, \"window\": 11, \"min_count\": 19, \"sample\": 0.008095572578952173, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 0, \"negative\": 80, \"ns_exponent\": -0.2792162520850042, \"cbow_mean\": 1, \"epochs\": 36}  \n",
       "247                     {\"vector_size\": 58, \"alpha\": 0.07503094453882388, \"window\": 10, \"min_count\": 19, \"sample\": 0.001191232125568951, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 0, \"negative\": 77, \"ns_exponent\": -0.0047230845895580575, \"cbow_mean\": 1, \"epochs\": 19}  \n",
       "158                            {\"vector_size\": 32, \"alpha\": 0.0592128459128618, \"window\": 8, \"min_count\": 20, \"sample\": 0.00621395156480427, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 157, \"ns_exponent\": 0.7467783161922974, \"cbow_mean\": 0, \"epochs\": 8}  \n",
       "237                                     {\"vector_size\": 32, \"alpha\": 0.05707874099191671, \"window\": 20, \"min_count\": 20, \"sample\": 0.0017640328213924257, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 39}  \n",
       "381                       {\"vector_size\": 32, \"alpha\": 0.06713281975747316, \"window\": 10, \"min_count\": 20, \"sample\": 0.009147429600951414, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 196, \"ns_exponent\": 0.48322770088098965, \"cbow_mean\": 1, \"epochs\": 27}  \n",
       "265     {\"vector_size\": 115, \"alpha\": 0.1015889721487536, \"window\": 8, \"min_count\": 19, \"sample\": 3.6059346565424594e-06, \"min_alpha\": 0.0003022076225879274, \"sg\": 1, \"hs\": 1, \"negative\": 124, \"ns_exponent\": 0.6576155402338049, \"cbow_mean\": 0, \"epochs\": 40}  \n",
       "116                                    {\"vector_size\": 172, \"alpha\": 0.01, \"window\": 20, \"min_count\": 9, \"sample\": 0.0028995593929572734, \"min_alpha\": 0.0020254675290314714, \"sg\": 1, \"hs\": 1, \"negative\": 1, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 37}  \n",
       "85                        {\"vector_size\": 32, \"alpha\": 0.05964574435135837, \"window\": 18, \"min_count\": 16, \"sample\": 0.008876134695306612, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 92, \"ns_exponent\": -0.09765205324600112, \"cbow_mean\": 0, \"epochs\": 35}  \n",
       "229                                      {\"vector_size\": 32, \"alpha\": 0.0474664122064446, \"window\": 20, \"min_count\": 20, \"sample\": 0.0004055060114277462, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": -0.5, \"cbow_mean\": 0, \"epochs\": 16}  \n",
       "135         {\"vector_size\": 180, \"alpha\": 0.07816659686491069, \"window\": 3, \"min_count\": 17, \"sample\": 0.0021995672391087835, \"min_alpha\": 0.00995155400961014, \"sg\": 1, \"hs\": 1, \"negative\": 1, \"ns_exponent\": 0.6811876909333345, \"cbow_mean\": 0, \"epochs\": 35}  \n",
       "352    {\"vector_size\": 114, \"alpha\": 0.045373170055526664, \"window\": 16, \"min_count\": 11, \"sample\": 0.005130252073538585, \"min_alpha\": 0.002673278398009932, \"sg\": 1, \"hs\": 0, \"negative\": 78, \"ns_exponent\": -0.42970032269339087, \"cbow_mean\": 0, \"epochs\": 40}  \n",
       "285         {\"vector_size\": 35, \"alpha\": 0.0872668924916005, \"window\": 3, \"min_count\": 7, \"sample\": 0.001987996448905776, \"min_alpha\": 0.0010214921011748672, \"sg\": 1, \"hs\": 1, \"negative\": 194, \"ns_exponent\": 0.7718502734409334, \"cbow_mean\": 1, \"epochs\": 20}  \n",
       "272                        {\"vector_size\": 32, \"alpha\": 0.07005874796139837, \"window\": 20, \"min_count\": 20, \"sample\": 0.0003311200732357621, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 32, \"ns_exponent\": 0.5332718088026134, \"cbow_mean\": 1, \"epochs\": 12}  \n",
       "348       {\"vector_size\": 32, \"alpha\": 0.03296252874183587, \"window\": 20, \"min_count\": 20, \"sample\": 0.007393817307345747, \"min_alpha\": 0.005249290049631279, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": 0.4095251313053274, \"cbow_mean\": 1, \"epochs\": 38}  \n",
       "277        {\"vector_size\": 51, \"alpha\": 0.11963179123406989, \"window\": 13, \"min_count\": 18, \"sample\": 0.009623849435582253, \"min_alpha\": 0.006799187345371015, \"sg\": 1, \"hs\": 1, \"negative\": 48, \"ns_exponent\": 1.4219775036375866, \"cbow_mean\": 1, \"epochs\": 13}  \n",
       "181                                      {\"vector_size\": 32, \"alpha\": 0.053289420357238854, \"window\": 20, \"min_count\": 20, \"sample\": 0.0, \"min_alpha\": 0.00484474251658218, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": -0.5, \"cbow_mean\": 0, \"epochs\": 17}  \n",
       "214        {\"vector_size\": 32, \"alpha\": 0.0480851457233036, \"window\": 17, \"min_count\": 14, \"sample\": 0.002186861353368606, \"min_alpha\": 0.007019512688849859, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": 1.1322950878847287, \"cbow_mean\": 0, \"epochs\": 40}  \n",
       "95         {\"vector_size\": 72, \"alpha\": 0.09650448934046392, \"window\": 2, \"min_count\": 19, \"sample\": 0.005057896428504944, \"min_alpha\": 0.009255123151381757, \"sg\": 0, \"hs\": 1, \"negative\": 38, \"ns_exponent\": -0.4645316224117231, \"cbow_mean\": 1, \"epochs\": 21}  \n",
       "115                                                        {\"vector_size\": 85, \"alpha\": 0.04449712042762617, \"window\": 20, \"min_count\": 1, \"sample\": 0.0, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 200, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 13}  \n",
       "79       {\"vector_size\": 504, \"alpha\": 0.015520861060438186, \"window\": 20, \"min_count\": 20, \"sample\": 0.00778376984373306, \"min_alpha\": 0.001997015119017354, \"sg\": 1, \"hs\": 1, \"negative\": 147, \"ns_exponent\": 1.4087472665471947, \"cbow_mean\": 1, \"epochs\": 15}  \n",
       "246                                          {\"vector_size\": 32, \"alpha\": 0.07003652844830963, \"window\": 8, \"min_count\": 5, \"sample\": 0.008340867774243746, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 1, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 40}  \n",
       "117                                                   {\"vector_size\": 512, \"alpha\": 0.01, \"window\": 20, \"min_count\": 10, \"sample\": 0.0013313031880266232, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 165, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 34}  \n",
       "175                                       {\"vector_size\": 32, \"alpha\": 0.01, \"window\": 20, \"min_count\": 9, \"sample\": 0.007925337107496691, \"min_alpha\": 0.005668805235168937, \"sg\": 1, \"hs\": 1, \"negative\": 8, \"ns_exponent\": -0.5, \"cbow_mean\": 0, \"epochs\": 33}  \n",
       "113  {\"vector_size\": 477, \"alpha\": 0.020771681778074966, \"window\": 11, \"min_count\": 9, \"sample\": 0.0012068933106558091, \"min_alpha\": 0.0001430591941553783, \"sg\": 1, \"hs\": 1, \"negative\": 24, \"ns_exponent\": 0.0032201764725420245, \"cbow_mean\": 0, \"epochs\": 23}  \n",
       "50                                                          {\"vector_size\": 168, \"alpha\": 0.01, \"window\": 1, \"min_count\": 6, \"sample\": 0.00573955047897152, \"min_alpha\": 0.01, \"sg\": 1, \"hs\": 1, \"negative\": 1, \"ns_exponent\": 1.5, \"cbow_mean\": 1, \"epochs\": 21}  \n",
       "351           {\"vector_size\": 32, \"alpha\": 0.105968801398386, \"window\": 17, \"min_count\": 20, \"sample\": 0.00355566201855149, \"min_alpha\": 0.007633278704116434, \"sg\": 1, \"hs\": 1, \"negative\": 20, \"ns_exponent\": 0.1905807522431322, \"cbow_mean\": 0, \"epochs\": 37}  \n",
       "311     {\"vector_size\": 306, \"alpha\": 0.06147667483695896, \"window\": 10, \"min_count\": 20, \"sample\": 0.003927505628049303, \"min_alpha\": 0.007522263025511343, \"sg\": 0, \"hs\": 0, \"negative\": 55, \"ns_exponent\": 0.026826698483518263, \"cbow_mean\": 1, \"epochs\": 27}  \n",
       "87        {\"vector_size\": 247, \"alpha\": 0.15721826024066973, \"window\": 19, \"min_count\": 20, \"sample\": 0.007150874316991576, \"min_alpha\": 0.004374968220954116, \"sg\": 0, \"hs\": 0, \"negative\": 19, \"ns_exponent\": 1.4829970741937542, \"cbow_mean\": 1, \"epochs\": 33}  \n",
       "374                                           {\"vector_size\": 32, \"alpha\": 0.01, \"window\": 20, \"min_count\": 20, \"sample\": 0.0, \"min_alpha\": 0.0053524322356035, \"sg\": 1, \"hs\": 1, \"negative\": 1, \"ns_exponent\": 0.7308747412887151, \"cbow_mean\": 1, \"epochs\": 40}  \n",
       "38                                         {\"vector_size\": 32, \"alpha\": 0.01, \"window\": 1, \"min_count\": 18, \"sample\": 0.0067685302199028555, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 1, \"ns_exponent\": -0.12062004630240025, \"cbow_mean\": 1, \"epochs\": 9}  \n",
       "314                                         {\"vector_size\": 32, \"alpha\": 0.01, \"window\": 2, \"min_count\": 8, \"sample\": 0.004975520058055087, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 1, \"negative\": 169, \"ns_exponent\": 1.0636377522530895, \"cbow_mean\": 0, \"epochs\": 22}  \n",
       "234     {\"vector_size\": 346, \"alpha\": 0.08533824204282285, \"window\": 19, \"min_count\": 16, \"sample\": 0.0032412756663735606, \"min_alpha\": 0.00018735795849837426, \"sg\": 1, \"hs\": 1, \"negative\": 4, \"ns_exponent\": 1.4947454752362213, \"cbow_mean\": 0, \"epochs\": 39}  \n",
       "384   {\"vector_size\": 488, \"alpha\": 0.07978395359109582, \"window\": 12, \"min_count\": 20, \"sample\": 0.0036862826710160734, \"min_alpha\": 0.005246774938026982, \"sg\": 1, \"hs\": 0, \"negative\": 21, \"ns_exponent\": -0.006832345614956381, \"cbow_mean\": 1, \"epochs\": 23}  \n",
       "304                                    {\"vector_size\": 110, \"alpha\": 0.050423676828064694, \"window\": 20, \"min_count\": 19, \"sample\": 0.008123428665266557, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 0, \"negative\": 200, \"ns_exponent\": -0.5, \"cbow_mean\": 0, \"epochs\": 34}  \n",
       "392        {\"vector_size\": 334, \"alpha\": 0.015520702321516127, \"window\": 17, \"min_count\": 19, \"sample\": 0.001199561847985863, \"min_alpha\": 0.008349294986079586, \"sg\": 1, \"hs\": 1, \"negative\": 3, \"ns_exponent\": 1.4272009721187031, \"cbow_mean\": 1, \"epochs\": 5}  \n",
       "361                                      {\"vector_size\": 94, \"alpha\": 0.06947270236917544, \"window\": 1, \"min_count\": 17, \"sample\": 0.0002136961736272643, \"min_alpha\": 0.01, \"sg\": 1, \"hs\": 1, \"negative\": 167, \"ns_exponent\": 1.5, \"cbow_mean\": 1, \"epochs\": 11}  \n",
       "213       {\"vector_size\": 84, \"alpha\": 0.012598763642146597, \"window\": 15, \"min_count\": 1, \"sample\": 0.005332893476479776, \"min_alpha\": 0.0021431676191946496, \"sg\": 1, \"hs\": 1, \"negative\": 71, \"ns_exponent\": 1.4876674649477886, \"cbow_mean\": 1, \"epochs\": 13}  \n",
       "322     {\"vector_size\": 219, \"alpha\": 0.010532155940595088, \"window\": 20, \"min_count\": 17, \"sample\": 0.002596885666587699, \"min_alpha\": 0.007035468385230185, \"sg\": 0, \"hs\": 1, \"negative\": 52, \"ns_exponent\": 0.002409712203672254, \"cbow_mean\": 1, \"epochs\": 6}  \n",
       "382         {\"vector_size\": 69, \"alpha\": 0.01019818022715307, \"window\": 6, \"min_count\": 20, \"sample\": 0.004502991639412014, \"min_alpha\": 0.00480787924893628, \"sg\": 1, \"hs\": 0, \"negative\": 144, \"ns_exponent\": 0.4413687399264423, \"cbow_mean\": 0, \"epochs\": 24}  \n",
       "130      {\"vector_size\": 286, \"alpha\": 0.14295874537849584, \"window\": 11, \"min_count\": 17, \"sample\": 0.003687185472403522, \"min_alpha\": 0.008709956417240641, \"sg\": 0, \"hs\": 0, \"negative\": 8, \"ns_exponent\": -0.46001165624864754, \"cbow_mean\": 1, \"epochs\": 21}  \n",
       "254    {\"vector_size\": 485, \"alpha\": 0.12049588890181084, \"window\": 5, \"min_count\": 18, \"sample\": 0.0014053117205029167, \"min_alpha\": 0.0036341585673360906, \"sg\": 0, \"hs\": 0, \"negative\": 123, \"ns_exponent\": -0.05898583722673212, \"cbow_mean\": 1, \"epochs\": 8}  \n",
       "216         {\"vector_size\": 81, \"alpha\": 0.10085489690278043, \"window\": 2, \"min_count\": 20, \"sample\": 0.008923419484562661, \"min_alpha\": 0.009385140728705138, \"sg\": 0, \"hs\": 1, \"negative\": 79, \"ns_exponent\": 1.1931504773134571, \"cbow_mean\": 1, \"epochs\": 28}  \n",
       "289                       {\"vector_size\": 32, \"alpha\": 0.06396030196382446, \"window\": 3, \"min_count\": 18, \"sample\": 0.004364170938095114, \"min_alpha\": 0.008907990434193486, \"sg\": 1, \"hs\": 0, \"negative\": 136, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 7}  \n",
       "202    {\"vector_size\": 512, \"alpha\": 0.10463926379679948, \"window\": 18, \"min_count\": 14, \"sample\": 0.005000081960071909, \"min_alpha\": 0.0030152634762777115, \"sg\": 1, \"hs\": 1, \"negative\": 91, \"ns_exponent\": -0.48682123012667966, \"cbow_mean\": 1, \"epochs\": 18}  \n",
       "182                      {\"vector_size\": 101, \"alpha\": 0.05464686732188873, \"window\": 20, \"min_count\": 18, \"sample\": 0.0001696930997441109, \"min_alpha\": 0.0, \"sg\": 1, \"hs\": 0, \"negative\": 200, \"ns_exponent\": 1.4094618736021645, \"cbow_mean\": 1, \"epochs\": 28}  \n",
       "155        {\"vector_size\": 297, \"alpha\": 0.09082082551852323, \"window\": 8, \"min_count\": 4, \"sample\": 0.005696184059233068, \"min_alpha\": 0.007037372792899164, \"sg\": 0, \"hs\": 0, \"negative\": 151, \"ns_exponent\": 0.2921965508467248, \"cbow_mean\": 1, \"epochs\": 27}  \n",
       "102                                                     {\"vector_size\": 224, \"alpha\": 0.01, \"window\": 1, \"min_count\": 20, \"sample\": 0.005601902299240549, \"min_alpha\": 0.01, \"sg\": 0, \"hs\": 1, \"negative\": 28, \"ns_exponent\": -0.5, \"cbow_mean\": 0, \"epochs\": 37}  \n",
       "365                                      {\"vector_size\": 32, \"alpha\": 0.01, \"window\": 9, \"min_count\": 12, \"sample\": 0.0006659733641450339, \"min_alpha\": 0.01, \"sg\": 1, \"hs\": 0, \"negative\": 200, \"ns_exponent\": 0.7879738877270659, \"cbow_mean\": 0, \"epochs\": 11}  \n",
       "104         {\"vector_size\": 511, \"alpha\": 0.16839306146958033, \"window\": 19, \"min_count\": 20, \"sample\": 0.009149999666668995, \"min_alpha\": 0.008135071910738, \"sg\": 0, \"hs\": 0, \"negative\": 18, \"ns_exponent\": -0.2943499232472799, \"cbow_mean\": 0, \"epochs\": 23}  \n",
       "363                        {\"vector_size\": 154, \"alpha\": 0.06336151461857757, \"window\": 16, \"min_count\": 18, \"sample\": 0.0, \"min_alpha\": 0.005447823572048148, \"sg\": 0, \"hs\": 1, \"negative\": 28, \"ns_exponent\": 1.1618514164550806, \"cbow_mean\": 0, \"epochs\": 11}  \n",
       "252     {\"vector_size\": 466, \"alpha\": 0.02561243587791314, \"window\": 8, \"min_count\": 19, \"sample\": 0.00015373822710633447, \"min_alpha\": 0.00014660082156420603, \"sg\": 1, \"hs\": 0, \"negative\": 6, \"ns_exponent\": 0.3007970430992072, \"cbow_mean\": 1, \"epochs\": 30}  \n",
       "260      {\"vector_size\": 290, \"alpha\": 0.02367203087676724, \"window\": 5, \"min_count\": 2, \"sample\": 0.00043974041818537125, \"min_alpha\": 0.00980664394588597, \"sg\": 1, \"hs\": 1, \"negative\": 153, \"ns_exponent\": 0.22860986454186105, \"cbow_mean\": 0, \"epochs\": 12}  \n",
       "150         {\"vector_size\": 41, \"alpha\": 0.011490523704024595, \"window\": 5, \"min_count\": 12, \"sample\": 0.0007556188235372032, \"min_alpha\": 0.006382821443245606, \"sg\": 0, \"hs\": 0, \"negative\": 7, \"ns_exponent\": -0.436239363736715, \"cbow_mean\": 1, \"epochs\": 7}  \n",
       "80       {\"vector_size\": 387, \"alpha\": 0.042331695359167955, \"window\": 15, \"min_count\": 20, \"sample\": 0.003325514745769446, \"min_alpha\": 0.002437153954900149, \"sg\": 1, \"hs\": 0, \"negative\": 1, \"ns_exponent\": 0.42059012366757476, \"cbow_mean\": 1, \"epochs\": 16}  \n",
       "251                       {\"vector_size\": 32, \"alpha\": 0.01, \"window\": 5, \"min_count\": 17, \"sample\": 0.006890079946580023, \"min_alpha\": 0.009720077650809908, \"sg\": 1, \"hs\": 0, \"negative\": 1, \"ns_exponent\": -0.29376940761134973, \"cbow_mean\": 1, \"epochs\": 40}  \n",
       "159                                                    {\"vector_size\": 512, \"alpha\": 0.01, \"window\": 1, \"min_count\": 20, \"sample\": 0.005959587789397423, \"min_alpha\": 0.01, \"sg\": 1, \"hs\": 0, \"negative\": 200, \"ns_exponent\": -0.5, \"cbow_mean\": 1, \"epochs\": 21}  \n",
       "332       {\"vector_size\": 495, \"alpha\": 0.0189264861206375, \"window\": 10, \"min_count\": 10, \"sample\": 0.006556153027161558, \"min_alpha\": 0.002600686794933334, \"sg\": 0, \"hs\": 1, \"negative\": 49, \"ns_exponent\": 0.11132447133617196, \"cbow_mean\": 0, \"epochs\": 33}  \n",
       "142     {\"vector_size\": 95, \"alpha\": 0.03175134619622058, \"window\": 14, \"min_count\": 8, \"sample\": 0.004458775530438851, \"min_alpha\": 0.0005646144847740984, \"sg\": 0, \"hs\": 0, \"negative\": 133, \"ns_exponent\": -0.44683445677283323, \"cbow_mean\": 0, \"epochs\": 12}  \n",
       "149        {\"vector_size\": 478, \"alpha\": 0.019651823643549608, \"window\": 2, \"min_count\": 15, \"sample\": 0.00689764288350841, \"min_alpha\": 0.008368164152911388, \"sg\": 0, \"hs\": 0, \"negative\": 40, \"ns_exponent\": 1.2630911248973271, \"cbow_mean\": 0, \"epochs\": 35}  \n",
       "59           {\"vector_size\": 56, \"alpha\": 0.1589967917140891, \"window\": 1, \"min_count\": 20, \"sample\": 0.004232113306278263, \"min_alpha\": 0.008365324155197177, \"sg\": 1, \"hs\": 0, \"negative\": 59, \"ns_exponent\": 0.5999024378800428, \"cbow_mean\": 1, \"epochs\": 39}  \n",
       "120       {\"vector_size\": 34, \"alpha\": 0.012719917840200268, \"window\": 7, \"min_count\": 19, \"sample\": 0.009497752742463693, \"min_alpha\": 0.001366708434511347, \"sg\": 0, \"hs\": 0, \"negative\": 161, \"ns_exponent\": 0.6351815658775408, \"cbow_mean\": 0, \"epochs\": 37}  \n",
       "128    {\"vector_size\": 512, \"alpha\": 0.20713706002361992, \"window\": 19, \"min_count\": 11, \"sample\": 0.001436781332807328, \"min_alpha\": 0.0003810483617761696, \"sg\": 1, \"hs\": 0, \"negative\": 127, \"ns_exponent\": 0.10294654184641983, \"cbow_mean\": 0, \"epochs\": 12}  \n",
       "298       {\"vector_size\": 324, \"alpha\": 0.16927314221409276, \"window\": 2, \"min_count\": 13, \"sample\": 0.009589492686245206, \"min_alpha\": 0.006527903170054909, \"sg\": 1, \"hs\": 1, \"negative\": 117, \"ns_exponent\": 0.3287371764527378, \"cbow_mean\": 0, \"epochs\": 27}  \n",
       "388    {\"vector_size\": 95, \"alpha\": 0.12792192564599866, \"window\": 14, \"min_count\": 19, \"sample\": 0.004519611550970182, \"min_alpha\": 3.7698902602270056e-05, \"sg\": 0, \"hs\": 1, \"negative\": 56, \"ns_exponent\": -0.34366781025479254, \"cbow_mean\": 0, \"epochs\": 34}  \n",
       "75         {\"vector_size\": 32, \"alpha\": 0.08242618134967342, \"window\": 11, \"min_count\": 2, \"sample\": 0.003638856047086074, \"min_alpha\": 0.009263806843660108, \"sg\": 0, \"hs\": 1, \"negative\": 198, \"ns_exponent\": -0.4261338108513455, \"cbow_mean\": 0, \"epochs\": 6}  \n",
       "176          {\"vector_size\": 292, \"alpha\": 0.46170756556905423, \"window\": 5, \"min_count\": 8, \"sample\": 0.0002703782169606418, \"min_alpha\": 0.009999089673847553, \"sg\": 1, \"hs\": 0, \"negative\": 7, \"ns_exponent\": 1.044038030841851, \"cbow_mean\": 1, \"epochs\": 39}  \n",
       "1        {\"vector_size\": 317, \"alpha\": 0.4236902168046986, \"window\": 17, \"min_count\": 17, \"sample\": 0.006235636967859725, \"min_alpha\": 0.0038438170729269993, \"sg\": 0, \"hs\": 0, \"negative\": 55, \"ns_exponent\": 0.45533023464269995, \"cbow_mean\": 1, \"epochs\": 22}  \n",
       "180                          {\"vector_size\": 193, \"alpha\": 0.06334327011492613, \"window\": 1, \"min_count\": 1, \"sample\": 0.0014004799353865209, \"min_alpha\": 0.01, \"sg\": 1, \"hs\": 0, \"negative\": 1, \"ns_exponent\": 1.313341870837467, \"cbow_mean\": 0, \"epochs\": 29}  \n",
       "15                                                       {\"vector_size\": 512, \"alpha\": 0.01, \"window\": 19, \"min_count\": 1, \"sample\": 0.00522451979904354, \"min_alpha\": 0.01, \"sg\": 1, \"hs\": 0, \"negative\": 113, \"ns_exponent\": 1.5, \"cbow_mean\": 1, \"epochs\": 26}  \n",
       "369          {\"vector_size\": 57, \"alpha\": 0.18647605732198, \"window\": 7, \"min_count\": 2, \"sample\": 0.006174535865558141, \"min_alpha\": 0.0004709690075481433, \"sg\": 1, \"hs\": 0, \"negative\": 170, \"ns_exponent\": -0.4619606993180334, \"cbow_mean\": 0, \"epochs\": 38}  \n",
       "224        {\"vector_size\": 419, \"alpha\": 0.4907507168868534, \"window\": 1, \"min_count\": 6, \"sample\": 0.006581227344786839, \"min_alpha\": 0.0011467590278891517, \"sg\": 0, \"hs\": 0, \"negative\": 73, \"ns_exponent\": -0.4410081695468102, \"cbow_mean\": 0, \"epochs\": 11}  \n",
       "389        {\"vector_size\": 321, \"alpha\": 0.25970303807785283, \"window\": 15, \"min_count\": 1, \"sample\": 0.0014462423092202472, \"min_alpha\": 0.005766934487021346, \"sg\": 1, \"hs\": 1, \"negative\": 4, \"ns_exponent\": 0.35034395292792997, \"cbow_mean\": 0, \"epochs\": 6}  \n",
       "194         {\"vector_size\": 460, \"alpha\": 0.3432272290370721, \"window\": 10, \"min_count\": 20, \"sample\": 0.0011620190961239443, \"min_alpha\": 0.00767023703558727, \"sg\": 0, \"hs\": 1, \"negative\": 51, \"ns_exponent\": 0.126436663891902, \"cbow_mean\": 1, \"epochs\": 26}  \n",
       "218     {\"vector_size\": 38, \"alpha\": 0.4888402826846181, \"window\": 11, \"min_count\": 2, \"sample\": 0.006552129382665774, \"min_alpha\": 0.0001860573563738688, \"sg\": 0, \"hs\": 0, \"negative\": 113, \"ns_exponent\": -0.025880124487907996, \"cbow_mean\": 1, \"epochs\": 34}  \n",
       "73       {\"vector_size\": 38, \"alpha\": 0.30080127542618607, \"window\": 20, \"min_count\": 4, \"sample\": 0.0013893804388576583, \"min_alpha\": 0.005984067181448116, \"sg\": 0, \"hs\": 0, \"negative\": 157, \"ns_exponent\": -0.4556266115057819, \"cbow_mean\": 1, \"epochs\": 29}  \n",
       "52                          {\"vector_size\": 504, \"alpha\": 0.5, \"window\": 5, \"min_count\": 1, \"sample\": 0.009992306440154147, \"min_alpha\": 0.007124425193490977, \"sg\": 0, \"hs\": 0, \"negative\": 200, \"ns_exponent\": 1.0727015353089016, \"cbow_mean\": 1, \"epochs\": 6}  \n",
       "222         {\"vector_size\": 37, \"alpha\": 0.3632297916313799, \"window\": 20, \"min_count\": 19, \"sample\": 0.009648740656265226, \"min_alpha\": 0.00794328012630056, \"sg\": 1, \"hs\": 0, \"negative\": 118, \"ns_exponent\": 1.2123906052541904, \"cbow_mean\": 1, \"epochs\": 34}  \n",
       "140      {\"vector_size\": 494, \"alpha\": 0.49959985706773874, \"window\": 14, \"min_count\": 19, \"sample\": 0.005034269304000619, \"min_alpha\": 0.0037266615183304645, \"sg\": 1, \"hs\": 1, \"negative\": 26, \"ns_exponent\": 1.2031417823782617, \"cbow_mean\": 0, \"epochs\": 37}  \n",
       "16       {\"vector_size\": 447, \"alpha\": 0.25939479072683713, \"window\": 18, \"min_count\": 19, \"sample\": 0.000831124926306024, \"min_alpha\": 0.002777185612810325, \"sg\": 0, \"hs\": 1, \"negative\": 130, \"ns_exponent\": 1.1827722383947092, \"cbow_mean\": 0, \"epochs\": 19}  \n",
       "244         {\"vector_size\": 194, \"alpha\": 0.3406286379069202, \"window\": 7, \"min_count\": 16, \"sample\": 0.009495710534507424, \"min_alpha\": 0.006625268669500444, \"sg\": 0, \"hs\": 1, \"negative\": 135, \"ns_exponent\": 1.443890004999332, \"cbow_mean\": 1, \"epochs\": 23}  \n",
       "168     {\"vector_size\": 139, \"alpha\": 0.1993796007516724, \"window\": 18, \"min_count\": 10, \"sample\": 0.006130634578841325, \"min_alpha\": 0.009023485831739845, \"sg\": 0, \"hs\": 1, \"negative\": 131, \"ns_exponent\": -0.15818082972790964, \"cbow_mean\": 0, \"epochs\": 31}  \n",
       "263        {\"vector_size\": 59, \"alpha\": 0.23106801511525482, \"window\": 1, \"min_count\": 9, \"sample\": 0.009795867288127287, \"min_alpha\": 0.0035944446396932155, \"sg\": 0, \"hs\": 1, \"negative\": 176, \"ns_exponent\": 1.3364709327242899, \"cbow_mean\": 0, \"epochs\": 25}  \n",
       "49                      {\"vector_size\": 50, \"alpha\": 0.5, \"window\": 8, \"min_count\": 15, \"sample\": 0.00041411145488896666, \"min_alpha\": 0.0011546154951504507, \"sg\": 1, \"hs\": 1, \"negative\": 84, \"ns_exponent\": -0.2898992160137226, \"cbow_mean\": 1, \"epochs\": 17}  \n",
       "279   {\"vector_size\": 378, \"alpha\": 0.29518969811680257, \"window\": 11, \"min_count\": 15, \"sample\": 0.0010590760718779215, \"min_alpha\": 0.0047360041934665755, \"sg\": 0, \"hs\": 1, \"negative\": 44, \"ns_exponent\": -0.22956365318909583, \"cbow_mean\": 0, \"epochs\": 10}  \n",
       "364           {\"vector_size\": 221, \"alpha\": 0.4196785941333151, \"window\": 7, \"min_count\": 13, \"sample\": 0.00368241539840548, \"min_alpha\": 0.009571551589530465, \"sg\": 0, \"hs\": 1, \"negative\": 95, \"ns_exponent\": 1.101821503959289, \"cbow_mean\": 1, \"epochs\": 29}  \n",
       "43        {\"vector_size\": 241, \"alpha\": 0.357124731406364, \"window\": 16, \"min_count\": 2, \"sample\": 0.007067355100237635, \"min_alpha\": 0.0001671380508565679, \"sg\": 1, \"hs\": 1, \"negative\": 119, \"ns_exponent\": -0.16720859807727279, \"cbow_mean\": 0, \"epochs\": 9}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_model_results(\"prod2vec\", paths.tuning_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RP3Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.6144719800572335, 'beta': 0.1443548354869016}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>score</th>\n",
       "      <th>model_parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031163</td>\n",
       "      <td>{\"alpha\": 0.6144719800572335, \"beta\": 0.1443548354869016}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031157</td>\n",
       "      <td>{\"alpha\": 0.6181427429215417, \"beta\": 0.1568063913815492}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031153</td>\n",
       "      <td>{\"alpha\": 0.6425523637511839, \"beta\": 0.12000161229109364}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031147</td>\n",
       "      <td>{\"alpha\": 0.6194830978040609, \"beta\": 0.1440006072122744}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031147</td>\n",
       "      <td>{\"alpha\": 0.6098548544210374, \"beta\": 0.1640913227647575}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031137</td>\n",
       "      <td>{\"alpha\": 0.6154834393253612, \"beta\": 0.13041106194937174}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031137</td>\n",
       "      <td>{\"alpha\": 0.6210086082431877, \"beta\": 0.14535963768298285}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031137</td>\n",
       "      <td>{\"alpha\": 0.6074075265396727, \"beta\": 0.14541695752927525}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031133</td>\n",
       "      <td>{\"alpha\": 0.6199754925154676, \"beta\": 0.1297884398553492}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031133</td>\n",
       "      <td>{\"alpha\": 0.619522136179538, \"beta\": 0.1301677275061156}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031133</td>\n",
       "      <td>{\"alpha\": 0.620118202368651, \"beta\": 0.12981438673752127}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031133</td>\n",
       "      <td>{\"alpha\": 0.6337288714251227, \"beta\": 0.14540959347674937}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031130</td>\n",
       "      <td>{\"alpha\": 0.6202628538685714, \"beta\": 0.12929140711483797}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031130</td>\n",
       "      <td>{\"alpha\": 0.6198742571532072, \"beta\": 0.12933539294212756}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031130</td>\n",
       "      <td>{\"alpha\": 0.6201631165761238, \"beta\": 0.12947277411469352}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031130</td>\n",
       "      <td>{\"alpha\": 0.6080915579453715, \"beta\": 0.14525412960243192}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031127</td>\n",
       "      <td>{\"alpha\": 0.6283532337259532, \"beta\": 0.13639492043862228}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031127</td>\n",
       "      <td>{\"alpha\": 0.6079670970689577, \"beta\": 0.14542160959658823}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031127</td>\n",
       "      <td>{\"alpha\": 0.6062743409498899, \"beta\": 0.14660675344522764}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031123</td>\n",
       "      <td>{\"alpha\": 0.6071735066308964, \"beta\": 0.14597076744628057}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031123</td>\n",
       "      <td>{\"alpha\": 0.6441816479806145, \"beta\": 0.1142266975255779}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031123</td>\n",
       "      <td>{\"alpha\": 0.6458262120403071, \"beta\": 0.11277697729693677}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031123</td>\n",
       "      <td>{\"alpha\": 0.6339283375685546, \"beta\": 0.14628414342108484}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031123</td>\n",
       "      <td>{\"alpha\": 0.6336768122435699, \"beta\": 0.14670711496019423}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031120</td>\n",
       "      <td>{\"alpha\": 0.6490007239453837, \"beta\": 0.11057208863212044}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031120</td>\n",
       "      <td>{\"alpha\": 0.6198228540644888, \"beta\": 0.14594215841347613}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031113</td>\n",
       "      <td>{\"alpha\": 0.6123508071986942, \"beta\": 0.1380689555887521}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031113</td>\n",
       "      <td>{\"alpha\": 0.6381841557627531, \"beta\": 0.1415050742825906}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031110</td>\n",
       "      <td>{\"alpha\": 0.6451692465071509, \"beta\": 0.12906954703683804}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031110</td>\n",
       "      <td>{\"alpha\": 0.576902725734489, \"beta\": 0.18681994097596893}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031110</td>\n",
       "      <td>{\"alpha\": 0.6173443583148153, \"beta\": 0.18095854434355646}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031110</td>\n",
       "      <td>{\"alpha\": 0.560812707888177, \"beta\": 0.19875037946128413}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031107</td>\n",
       "      <td>{\"alpha\": 0.649393764741673, \"beta\": 0.12832811224194376}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031107</td>\n",
       "      <td>{\"alpha\": 0.6372431429340817, \"beta\": 0.13912312790801057}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031107</td>\n",
       "      <td>{\"alpha\": 0.6130489980503451, \"beta\": 0.17384491026805166}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031103</td>\n",
       "      <td>{\"alpha\": 0.650335145925419, \"beta\": 0.10969711398155234}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031103</td>\n",
       "      <td>{\"alpha\": 0.639844296508907, \"beta\": 0.12890328106551904}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031097</td>\n",
       "      <td>{\"alpha\": 0.5975944998520341, \"beta\": 0.15423757848358435}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031090</td>\n",
       "      <td>{\"alpha\": 0.643544149193211, \"beta\": 0.13226747413138187}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031083</td>\n",
       "      <td>{\"alpha\": 0.6675394939553753, \"beta\": 0.08413196446479514}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031083</td>\n",
       "      <td>{\"alpha\": 0.6421391731863338, \"beta\": 0.1535071893077171}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031080</td>\n",
       "      <td>{\"alpha\": 0.6045161667617673, \"beta\": 0.16892024314899787}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031053</td>\n",
       "      <td>{\"alpha\": 0.7217715073078479, \"beta\": 0.10280121823841669}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031053</td>\n",
       "      <td>{\"alpha\": 0.5950692130889447, \"beta\": 0.11342595463488639}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031043</td>\n",
       "      <td>{\"alpha\": 0.5855268150459079, \"beta\": 0.17155842774413563}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.031040</td>\n",
       "      <td>{\"alpha\": 0.563725133341124, \"beta\": 0.24989876227301427}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.030653</td>\n",
       "      <td>{\"alpha\": 0.41458812604897566, \"beta\": 0.35148162041033226}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.030623</td>\n",
       "      <td>{\"alpha\": 0.5664099283891625, \"beta\": 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.030447</td>\n",
       "      <td>{\"alpha\": 0.31119753730748717, \"beta\": 0.21382945425036246}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.029690</td>\n",
       "      <td>{\"alpha\": 0.7307988314174844, \"beta\": 0.3670824958804893}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.029637</td>\n",
       "      <td>{\"alpha\": 0.16723301407772298, \"beta\": 0.23308855565235836}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.029453</td>\n",
       "      <td>{\"alpha\": 0.9969984844741999, \"beta\": 0.002990876864926496}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.028567</td>\n",
       "      <td>{\"alpha\": 1.0730398402102277, \"beta\": 0.0556392303465172}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.028510</td>\n",
       "      <td>{\"alpha\": 0.00038685786121250853, \"beta\": 0.20612835448978634}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.028223</td>\n",
       "      <td>{\"alpha\": 0.001763462680447914, \"beta\": 0.4396037453368641}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.027967</td>\n",
       "      <td>{\"alpha\": 0.47683486365586625, \"beta\": 0.5477709355337247}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.027757</td>\n",
       "      <td>{\"alpha\": 1.0608747173497872, \"beta\": 0.19474109120641253}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.027567</td>\n",
       "      <td>{\"alpha\": 0.0, \"beta\": 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.026693</td>\n",
       "      <td>{\"alpha\": 1.0476495792050502, \"beta\": 0.3030634136778079}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.026093</td>\n",
       "      <td>{\"alpha\": 0.8632611573795697, \"beta\": 0.4797376541321926}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.024133</td>\n",
       "      <td>{\"alpha\": 1.2049092504784888, \"beta\": 0.3068405267488424}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.021827</td>\n",
       "      <td>{\"alpha\": 1.525517006292763, \"beta\": 0.09880324649784214}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.019360</td>\n",
       "      <td>{\"alpha\": 1.4617106987541304, \"beta\": 0.3746467271733494}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.018153</td>\n",
       "      <td>{\"alpha\": 0.008234802174600155, \"beta\": 0.7334073204203123}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.017873</td>\n",
       "      <td>{\"alpha\": 2.0, \"beta\": 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.017750</td>\n",
       "      <td>{\"alpha\": 1.730189268906794, \"beta\": 0.2880555122842406}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.016493</td>\n",
       "      <td>{\"alpha\": 1.9957562711095158, \"beta\": 0.19096187131762982}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.015520</td>\n",
       "      <td>{\"alpha\": 1.4704506911587711, \"beta\": 0.57623359861382}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.014023</td>\n",
       "      <td>{\"alpha\": 1.9849312618326016, \"beta\": 0.42953604053483774}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.012673</td>\n",
       "      <td>{\"alpha\": 1.247127393571945, \"beta\": 0.7687634145853999}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.010133</td>\n",
       "      <td>{\"alpha\": 1.9987617185957425, \"beta\": 0.7555859736266215}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>{\"alpha\": 1.6151147266755372, \"beta\": 0.8433399632996059}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.008740</td>\n",
       "      <td>{\"alpha\": 1.7467266939727688, \"beta\": 0.8958285646781865}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.008007</td>\n",
       "      <td>{\"alpha\": 1.6243374575509868, \"beta\": 0.9599543447501149}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.007950</td>\n",
       "      <td>{\"alpha\": 0.5453125891602265, \"beta\": 0.9553302346427}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.006310</td>\n",
       "      <td>{\"alpha\": 1.2664439363993303, \"beta\": 1.068096869011075}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.004927</td>\n",
       "      <td>{\"alpha\": 1.995124660782672, \"beta\": 1.2991229636302486}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>{\"alpha\": 1.4939744960475185, \"beta\": 1.2717933525293892}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>{\"alpha\": 1.4083717452608613, \"beta\": 1.3364116206993937}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>{\"alpha\": 1.1277200517257153, \"beta\": 1.2944988179999757}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.002977</td>\n",
       "      <td>{\"alpha\": 1.5864242931761428, \"beta\": 1.532025303602171}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>{\"alpha\": 0.4966966639976288, \"beta\": 1.1729060460953078}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.002670</td>\n",
       "      <td>{\"alpha\": 0.18007684672559268, \"beta\": 1.1009208134203539}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>{\"alpha\": 1.7913671300985219, \"beta\": 1.7025169702583876}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>{\"alpha\": 1.715891235245514, \"beta\": 1.6945034775682513}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>{\"alpha\": 0.6747923208345369, \"beta\": 1.2963437441023946}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>{\"alpha\": 1.9929589386490192, \"beta\": 1.9926470193240748}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>{\"alpha\": 0.0001272584672771249, \"beta\": 1.13470988607561}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>{\"alpha\": 1.1856892364500369, \"beta\": 1.688531497162035}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>{\"alpha\": 1.4121427391540047, \"beta\": 1.9989623566084869}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>{\"alpha\": 0.7855695922016597, \"beta\": 1.6721575270747555}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>{\"alpha\": 1.0761221522747149, \"beta\": 1.9198638584481944}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>{\"alpha\": 0.39022664024155895, \"beta\": 1.60872987858149}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>{\"alpha\": 0.736483079681096, \"beta\": 1.9143103179060932}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>{\"alpha\": 0.002701148488490013, \"beta\": 1.4627960257388104}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>{\"alpha\": 0.033096927713794695, \"beta\": 1.5129541996904574}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>{\"alpha\": 0.0646132205980219, \"beta\": 1.53477825859378}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>{\"alpha\": 0.28070156082529035, \"beta\": 1.7401745167168732}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>{\"alpha\": 0.14968075954400176, \"beta\": 1.7024706405904741}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>rp3beta</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>{\"alpha\": 0.005130046599823857, \"beta\": 1.997398930497995}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name     score  \\\n",
       "72     rp3beta  0.031163   \n",
       "198    rp3beta  0.031157   \n",
       "248    rp3beta  0.031153   \n",
       "375    rp3beta  0.031147   \n",
       "71     rp3beta  0.031147   \n",
       "172    rp3beta  0.031137   \n",
       "106    rp3beta  0.031137   \n",
       "395    rp3beta  0.031137   \n",
       "333    rp3beta  0.031133   \n",
       "396    rp3beta  0.031133   \n",
       "354    rp3beta  0.031133   \n",
       "196    rp3beta  0.031133   \n",
       "208    rp3beta  0.031130   \n",
       "223    rp3beta  0.031130   \n",
       "23     rp3beta  0.031130   \n",
       "11     rp3beta  0.031130   \n",
       "119    rp3beta  0.031127   \n",
       "215    rp3beta  0.031127   \n",
       "67     rp3beta  0.031127   \n",
       "68     rp3beta  0.031123   \n",
       "105    rp3beta  0.031123   \n",
       "356    rp3beta  0.031123   \n",
       "192    rp3beta  0.031123   \n",
       "380    rp3beta  0.031123   \n",
       "327    rp3beta  0.031120   \n",
       "40     rp3beta  0.031120   \n",
       "287    rp3beta  0.031113   \n",
       "111    rp3beta  0.031113   \n",
       "100    rp3beta  0.031110   \n",
       "20     rp3beta  0.031110   \n",
       "81     rp3beta  0.031110   \n",
       "64     rp3beta  0.031110   \n",
       "28     rp3beta  0.031107   \n",
       "318    rp3beta  0.031107   \n",
       "62     rp3beta  0.031107   \n",
       "0      rp3beta  0.031103   \n",
       "317    rp3beta  0.031103   \n",
       "286    rp3beta  0.031097   \n",
       "309    rp3beta  0.031090   \n",
       "126    rp3beta  0.031083   \n",
       "239    rp3beta  0.031083   \n",
       "245    rp3beta  0.031080   \n",
       "177    rp3beta  0.031053   \n",
       "78     rp3beta  0.031053   \n",
       "231    rp3beta  0.031043   \n",
       "137    rp3beta  0.031040   \n",
       "143    rp3beta  0.030653   \n",
       "379    rp3beta  0.030623   \n",
       "97     rp3beta  0.030447   \n",
       "320    rp3beta  0.029690   \n",
       "296    rp3beta  0.029637   \n",
       "242    rp3beta  0.029453   \n",
       "160    rp3beta  0.028567   \n",
       "65     rp3beta  0.028510   \n",
       "66     rp3beta  0.028223   \n",
       "193    rp3beta  0.027967   \n",
       "270    rp3beta  0.027757   \n",
       "42     rp3beta  0.027567   \n",
       "94     rp3beta  0.026693   \n",
       "164    rp3beta  0.026093   \n",
       "162    rp3beta  0.024133   \n",
       "101    rp3beta  0.021827   \n",
       "230    rp3beta  0.019360   \n",
       "350    rp3beta  0.018153   \n",
       "371    rp3beta  0.017873   \n",
       "278    rp3beta  0.017750   \n",
       "294    rp3beta  0.016493   \n",
       "103    rp3beta  0.015520   \n",
       "336    rp3beta  0.014023   \n",
       "10     rp3beta  0.012673   \n",
       "325    rp3beta  0.010133   \n",
       "256    rp3beta  0.009677   \n",
       "376    rp3beta  0.008740   \n",
       "166    rp3beta  0.008007   \n",
       "197    rp3beta  0.007950   \n",
       "51     rp3beta  0.006310   \n",
       "13     rp3beta  0.004927   \n",
       "394    rp3beta  0.004393   \n",
       "386    rp3beta  0.003703   \n",
       "349    rp3beta  0.003507   \n",
       "21     rp3beta  0.002977   \n",
       "124    rp3beta  0.002900   \n",
       "312    rp3beta  0.002670   \n",
       "291    rp3beta  0.002667   \n",
       "57     rp3beta  0.002597   \n",
       "74     rp3beta  0.002400   \n",
       "22     rp3beta  0.002217   \n",
       "33     rp3beta  0.001823   \n",
       "372    rp3beta  0.001780   \n",
       "118    rp3beta  0.001477   \n",
       "99     rp3beta  0.001290   \n",
       "366    rp3beta  0.001213   \n",
       "187    rp3beta  0.000883   \n",
       "184    rp3beta  0.000870   \n",
       "355    rp3beta  0.000713   \n",
       "339    rp3beta  0.000677   \n",
       "378    rp3beta  0.000667   \n",
       "343    rp3beta  0.000663   \n",
       "206    rp3beta  0.000617   \n",
       "171    rp3beta  0.000457   \n",
       "\n",
       "                                                   model_parameters  \n",
       "72        {\"alpha\": 0.6144719800572335, \"beta\": 0.1443548354869016}  \n",
       "198       {\"alpha\": 0.6181427429215417, \"beta\": 0.1568063913815492}  \n",
       "248      {\"alpha\": 0.6425523637511839, \"beta\": 0.12000161229109364}  \n",
       "375       {\"alpha\": 0.6194830978040609, \"beta\": 0.1440006072122744}  \n",
       "71        {\"alpha\": 0.6098548544210374, \"beta\": 0.1640913227647575}  \n",
       "172      {\"alpha\": 0.6154834393253612, \"beta\": 0.13041106194937174}  \n",
       "106      {\"alpha\": 0.6210086082431877, \"beta\": 0.14535963768298285}  \n",
       "395      {\"alpha\": 0.6074075265396727, \"beta\": 0.14541695752927525}  \n",
       "333       {\"alpha\": 0.6199754925154676, \"beta\": 0.1297884398553492}  \n",
       "396        {\"alpha\": 0.619522136179538, \"beta\": 0.1301677275061156}  \n",
       "354       {\"alpha\": 0.620118202368651, \"beta\": 0.12981438673752127}  \n",
       "196      {\"alpha\": 0.6337288714251227, \"beta\": 0.14540959347674937}  \n",
       "208      {\"alpha\": 0.6202628538685714, \"beta\": 0.12929140711483797}  \n",
       "223      {\"alpha\": 0.6198742571532072, \"beta\": 0.12933539294212756}  \n",
       "23       {\"alpha\": 0.6201631165761238, \"beta\": 0.12947277411469352}  \n",
       "11       {\"alpha\": 0.6080915579453715, \"beta\": 0.14525412960243192}  \n",
       "119      {\"alpha\": 0.6283532337259532, \"beta\": 0.13639492043862228}  \n",
       "215      {\"alpha\": 0.6079670970689577, \"beta\": 0.14542160959658823}  \n",
       "67       {\"alpha\": 0.6062743409498899, \"beta\": 0.14660675344522764}  \n",
       "68       {\"alpha\": 0.6071735066308964, \"beta\": 0.14597076744628057}  \n",
       "105       {\"alpha\": 0.6441816479806145, \"beta\": 0.1142266975255779}  \n",
       "356      {\"alpha\": 0.6458262120403071, \"beta\": 0.11277697729693677}  \n",
       "192      {\"alpha\": 0.6339283375685546, \"beta\": 0.14628414342108484}  \n",
       "380      {\"alpha\": 0.6336768122435699, \"beta\": 0.14670711496019423}  \n",
       "327      {\"alpha\": 0.6490007239453837, \"beta\": 0.11057208863212044}  \n",
       "40       {\"alpha\": 0.6198228540644888, \"beta\": 0.14594215841347613}  \n",
       "287       {\"alpha\": 0.6123508071986942, \"beta\": 0.1380689555887521}  \n",
       "111       {\"alpha\": 0.6381841557627531, \"beta\": 0.1415050742825906}  \n",
       "100      {\"alpha\": 0.6451692465071509, \"beta\": 0.12906954703683804}  \n",
       "20        {\"alpha\": 0.576902725734489, \"beta\": 0.18681994097596893}  \n",
       "81       {\"alpha\": 0.6173443583148153, \"beta\": 0.18095854434355646}  \n",
       "64        {\"alpha\": 0.560812707888177, \"beta\": 0.19875037946128413}  \n",
       "28        {\"alpha\": 0.649393764741673, \"beta\": 0.12832811224194376}  \n",
       "318      {\"alpha\": 0.6372431429340817, \"beta\": 0.13912312790801057}  \n",
       "62       {\"alpha\": 0.6130489980503451, \"beta\": 0.17384491026805166}  \n",
       "0         {\"alpha\": 0.650335145925419, \"beta\": 0.10969711398155234}  \n",
       "317       {\"alpha\": 0.639844296508907, \"beta\": 0.12890328106551904}  \n",
       "286      {\"alpha\": 0.5975944998520341, \"beta\": 0.15423757848358435}  \n",
       "309       {\"alpha\": 0.643544149193211, \"beta\": 0.13226747413138187}  \n",
       "126      {\"alpha\": 0.6675394939553753, \"beta\": 0.08413196446479514}  \n",
       "239       {\"alpha\": 0.6421391731863338, \"beta\": 0.1535071893077171}  \n",
       "245      {\"alpha\": 0.6045161667617673, \"beta\": 0.16892024314899787}  \n",
       "177      {\"alpha\": 0.7217715073078479, \"beta\": 0.10280121823841669}  \n",
       "78       {\"alpha\": 0.5950692130889447, \"beta\": 0.11342595463488639}  \n",
       "231      {\"alpha\": 0.5855268150459079, \"beta\": 0.17155842774413563}  \n",
       "137       {\"alpha\": 0.563725133341124, \"beta\": 0.24989876227301427}  \n",
       "143     {\"alpha\": 0.41458812604897566, \"beta\": 0.35148162041033226}  \n",
       "379                      {\"alpha\": 0.5664099283891625, \"beta\": 0.0}  \n",
       "97      {\"alpha\": 0.31119753730748717, \"beta\": 0.21382945425036246}  \n",
       "320       {\"alpha\": 0.7307988314174844, \"beta\": 0.3670824958804893}  \n",
       "296     {\"alpha\": 0.16723301407772298, \"beta\": 0.23308855565235836}  \n",
       "242     {\"alpha\": 0.9969984844741999, \"beta\": 0.002990876864926496}  \n",
       "160       {\"alpha\": 1.0730398402102277, \"beta\": 0.0556392303465172}  \n",
       "65   {\"alpha\": 0.00038685786121250853, \"beta\": 0.20612835448978634}  \n",
       "66      {\"alpha\": 0.001763462680447914, \"beta\": 0.4396037453368641}  \n",
       "193      {\"alpha\": 0.47683486365586625, \"beta\": 0.5477709355337247}  \n",
       "270      {\"alpha\": 1.0608747173497872, \"beta\": 0.19474109120641253}  \n",
       "42                                      {\"alpha\": 0.0, \"beta\": 0.0}  \n",
       "94        {\"alpha\": 1.0476495792050502, \"beta\": 0.3030634136778079}  \n",
       "164       {\"alpha\": 0.8632611573795697, \"beta\": 0.4797376541321926}  \n",
       "162       {\"alpha\": 1.2049092504784888, \"beta\": 0.3068405267488424}  \n",
       "101       {\"alpha\": 1.525517006292763, \"beta\": 0.09880324649784214}  \n",
       "230       {\"alpha\": 1.4617106987541304, \"beta\": 0.3746467271733494}  \n",
       "350     {\"alpha\": 0.008234802174600155, \"beta\": 0.7334073204203123}  \n",
       "371                                     {\"alpha\": 2.0, \"beta\": 0.0}  \n",
       "278        {\"alpha\": 1.730189268906794, \"beta\": 0.2880555122842406}  \n",
       "294      {\"alpha\": 1.9957562711095158, \"beta\": 0.19096187131762982}  \n",
       "103         {\"alpha\": 1.4704506911587711, \"beta\": 0.57623359861382}  \n",
       "336      {\"alpha\": 1.9849312618326016, \"beta\": 0.42953604053483774}  \n",
       "10         {\"alpha\": 1.247127393571945, \"beta\": 0.7687634145853999}  \n",
       "325       {\"alpha\": 1.9987617185957425, \"beta\": 0.7555859736266215}  \n",
       "256       {\"alpha\": 1.6151147266755372, \"beta\": 0.8433399632996059}  \n",
       "376       {\"alpha\": 1.7467266939727688, \"beta\": 0.8958285646781865}  \n",
       "166       {\"alpha\": 1.6243374575509868, \"beta\": 0.9599543447501149}  \n",
       "197          {\"alpha\": 0.5453125891602265, \"beta\": 0.9553302346427}  \n",
       "51         {\"alpha\": 1.2664439363993303, \"beta\": 1.068096869011075}  \n",
       "13         {\"alpha\": 1.995124660782672, \"beta\": 1.2991229636302486}  \n",
       "394       {\"alpha\": 1.4939744960475185, \"beta\": 1.2717933525293892}  \n",
       "386       {\"alpha\": 1.4083717452608613, \"beta\": 1.3364116206993937}  \n",
       "349       {\"alpha\": 1.1277200517257153, \"beta\": 1.2944988179999757}  \n",
       "21         {\"alpha\": 1.5864242931761428, \"beta\": 1.532025303602171}  \n",
       "124       {\"alpha\": 0.4966966639976288, \"beta\": 1.1729060460953078}  \n",
       "312      {\"alpha\": 0.18007684672559268, \"beta\": 1.1009208134203539}  \n",
       "291       {\"alpha\": 1.7913671300985219, \"beta\": 1.7025169702583876}  \n",
       "57         {\"alpha\": 1.715891235245514, \"beta\": 1.6945034775682513}  \n",
       "74        {\"alpha\": 0.6747923208345369, \"beta\": 1.2963437441023946}  \n",
       "22        {\"alpha\": 1.9929589386490192, \"beta\": 1.9926470193240748}  \n",
       "33       {\"alpha\": 0.0001272584672771249, \"beta\": 1.13470988607561}  \n",
       "372        {\"alpha\": 1.1856892364500369, \"beta\": 1.688531497162035}  \n",
       "118       {\"alpha\": 1.4121427391540047, \"beta\": 1.9989623566084869}  \n",
       "99        {\"alpha\": 0.7855695922016597, \"beta\": 1.6721575270747555}  \n",
       "366       {\"alpha\": 1.0761221522747149, \"beta\": 1.9198638584481944}  \n",
       "187        {\"alpha\": 0.39022664024155895, \"beta\": 1.60872987858149}  \n",
       "184        {\"alpha\": 0.736483079681096, \"beta\": 1.9143103179060932}  \n",
       "355     {\"alpha\": 0.002701148488490013, \"beta\": 1.4627960257388104}  \n",
       "339     {\"alpha\": 0.033096927713794695, \"beta\": 1.5129541996904574}  \n",
       "378         {\"alpha\": 0.0646132205980219, \"beta\": 1.53477825859378}  \n",
       "343      {\"alpha\": 0.28070156082529035, \"beta\": 1.7401745167168732}  \n",
       "206      {\"alpha\": 0.14968075954400176, \"beta\": 1.7024706405904741}  \n",
       "171      {\"alpha\": 0.005130046599823857, \"beta\": 1.997398930497995}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_model_results(\"rp3beta\", paths.tuning_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factors': 357,\n",
       " 'regularization': 0.001,\n",
       " 'iterations': 20,\n",
       " 'event_weights_multiplier': 63}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>score</th>\n",
       "      <th>model_parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>als</td>\n",
       "      <td>0.031713</td>\n",
       "      <td>{\"factors\": 357, \"regularization\": 0.001, \"iterations\": 20, \"event_weights_multiplier\": 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>als</td>\n",
       "      <td>0.031677</td>\n",
       "      <td>{\"factors\": 339, \"regularization\": 0.001, \"iterations\": 20, \"event_weights_multiplier\": 68}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>als</td>\n",
       "      <td>0.031637</td>\n",
       "      <td>{\"factors\": 505, \"regularization\": 0.012947035211209885, \"iterations\": 19, \"event_weights_multiplier\": 33}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>als</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>{\"factors\": 438, \"regularization\": 0.001, \"iterations\": 20, \"event_weights_multiplier\": 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>als</td>\n",
       "      <td>0.031520</td>\n",
       "      <td>{\"factors\": 512, \"regularization\": 0.001, \"iterations\": 20, \"event_weights_multiplier\": 24}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>als</td>\n",
       "      <td>0.031493</td>\n",
       "      <td>{\"factors\": 367, \"regularization\": 0.03905378902197729, \"iterations\": 9, \"event_weights_multiplier\": 38}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>als</td>\n",
       "      <td>0.031477</td>\n",
       "      <td>{\"factors\": 440, \"regularization\": 0.001, \"iterations\": 18, \"event_weights_multiplier\": 37}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>als</td>\n",
       "      <td>0.031473</td>\n",
       "      <td>{\"factors\": 366, \"regularization\": 0.001, \"iterations\": 20, \"event_weights_multiplier\": 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>als</td>\n",
       "      <td>0.031463</td>\n",
       "      <td>{\"factors\": 454, \"regularization\": 0.001, \"iterations\": 20, \"event_weights_multiplier\": 46}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>als</td>\n",
       "      <td>0.031433</td>\n",
       "      <td>{\"factors\": 423, \"regularization\": 0.001, \"iterations\": 20, \"event_weights_multiplier\": 75}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>als</td>\n",
       "      <td>0.031420</td>\n",
       "      <td>{\"factors\": 404, \"regularization\": 0.001, \"iterations\": 20, \"event_weights_multiplier\": 88}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>als</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>{\"factors\": 359, \"regularization\": 0.001, \"iterations\": 7, \"event_weights_multiplier\": 69}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>als</td>\n",
       "      <td>0.031357</td>\n",
       "      <td>{\"factors\": 407, \"regularization\": 0.040110586464738356, \"iterations\": 20, \"event_weights_multiplier\": 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>als</td>\n",
       "      <td>0.031333</td>\n",
       "      <td>{\"factors\": 341, \"regularization\": 0.001, \"iterations\": 18, \"event_weights_multiplier\": 79}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>als</td>\n",
       "      <td>0.031307</td>\n",
       "      <td>{\"factors\": 512, \"regularization\": 0.04306347380625003, \"iterations\": 16, \"event_weights_multiplier\": 46}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>als</td>\n",
       "      <td>0.031260</td>\n",
       "      <td>{\"factors\": 512, \"regularization\": 0.001, \"iterations\": 20, \"event_weights_multiplier\": 74}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>als</td>\n",
       "      <td>0.031257</td>\n",
       "      <td>{\"factors\": 386, \"regularization\": 0.001, \"iterations\": 14, \"event_weights_multiplier\": 92}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>als</td>\n",
       "      <td>0.031220</td>\n",
       "      <td>{\"factors\": 314, \"regularization\": 0.001, \"iterations\": 9, \"event_weights_multiplier\": 88}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>als</td>\n",
       "      <td>0.031127</td>\n",
       "      <td>{\"factors\": 512, \"regularization\": 0.001, \"iterations\": 16, \"event_weights_multiplier\": 77}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>als</td>\n",
       "      <td>0.031027</td>\n",
       "      <td>{\"factors\": 507, \"regularization\": 0.09215769067255868, \"iterations\": 5, \"event_weights_multiplier\": 13}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>als</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>{\"factors\": 350, \"regularization\": 0.09541667165691277, \"iterations\": 16, \"event_weights_multiplier\": 18}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>als</td>\n",
       "      <td>0.030980</td>\n",
       "      <td>{\"factors\": 309, \"regularization\": 0.09781390365598827, \"iterations\": 20, \"event_weights_multiplier\": 102}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>als</td>\n",
       "      <td>0.030927</td>\n",
       "      <td>{\"factors\": 211, \"regularization\": 0.014386599167139757, \"iterations\": 10, \"event_weights_multiplier\": 83}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>als</td>\n",
       "      <td>0.030913</td>\n",
       "      <td>{\"factors\": 512, \"regularization\": 0.03294001338708355, \"iterations\": 5, \"event_weights_multiplier\": 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>als</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>{\"factors\": 512, \"regularization\": 0.001, \"iterations\": 8, \"event_weights_multiplier\": 70}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>als</td>\n",
       "      <td>0.030787</td>\n",
       "      <td>{\"factors\": 512, \"regularization\": 0.001, \"iterations\": 11, \"event_weights_multiplier\": 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>als</td>\n",
       "      <td>0.030783</td>\n",
       "      <td>{\"factors\": 512, \"regularization\": 0.1, \"iterations\": 12, \"event_weights_multiplier\": 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>als</td>\n",
       "      <td>0.030750</td>\n",
       "      <td>{\"factors\": 399, \"regularization\": 0.1, \"iterations\": 8, \"event_weights_multiplier\": 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>als</td>\n",
       "      <td>0.030727</td>\n",
       "      <td>{\"factors\": 314, \"regularization\": 0.09168190060071142, \"iterations\": 20, \"event_weights_multiplier\": 18}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>als</td>\n",
       "      <td>0.030720</td>\n",
       "      <td>{\"factors\": 322, \"regularization\": 0.05571258804806584, \"iterations\": 13, \"event_weights_multiplier\": 89}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>als</td>\n",
       "      <td>0.030670</td>\n",
       "      <td>{\"factors\": 512, \"regularization\": 0.06307260070812636, \"iterations\": 20, \"event_weights_multiplier\": 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>als</td>\n",
       "      <td>0.030617</td>\n",
       "      <td>{\"factors\": 268, \"regularization\": 0.002217635176534642, \"iterations\": 20, \"event_weights_multiplier\": 168}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>als</td>\n",
       "      <td>0.030600</td>\n",
       "      <td>{\"factors\": 512, \"regularization\": 0.001, \"iterations\": 20, \"event_weights_multiplier\": 183}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>als</td>\n",
       "      <td>0.030437</td>\n",
       "      <td>{\"factors\": 347, \"regularization\": 0.002495442175096357, \"iterations\": 11, \"event_weights_multiplier\": 189}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>als</td>\n",
       "      <td>0.030397</td>\n",
       "      <td>{\"factors\": 503, \"regularization\": 0.09908839492644471, \"iterations\": 19, \"event_weights_multiplier\": 97}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>als</td>\n",
       "      <td>0.030213</td>\n",
       "      <td>{\"factors\": 327, \"regularization\": 0.001, \"iterations\": 12, \"event_weights_multiplier\": 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>als</td>\n",
       "      <td>0.030097</td>\n",
       "      <td>{\"factors\": 417, \"regularization\": 0.0064907955372548055, \"iterations\": 20, \"event_weights_multiplier\": 265}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>als</td>\n",
       "      <td>0.030047</td>\n",
       "      <td>{\"factors\": 276, \"regularization\": 0.003882720285079686, \"iterations\": 20, \"event_weights_multiplier\": 356}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>als</td>\n",
       "      <td>0.029993</td>\n",
       "      <td>{\"factors\": 497, \"regularization\": 0.0023673500229865977, \"iterations\": 14, \"event_weights_multiplier\": 233}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>als</td>\n",
       "      <td>0.029973</td>\n",
       "      <td>{\"factors\": 227, \"regularization\": 0.09990075038326883, \"iterations\": 14, \"event_weights_multiplier\": 150}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>als</td>\n",
       "      <td>0.029970</td>\n",
       "      <td>{\"factors\": 340, \"regularization\": 0.0010287944513174545, \"iterations\": 13, \"event_weights_multiplier\": 315}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>als</td>\n",
       "      <td>0.029907</td>\n",
       "      <td>{\"factors\": 273, \"regularization\": 0.001, \"iterations\": 5, \"event_weights_multiplier\": 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>als</td>\n",
       "      <td>0.029883</td>\n",
       "      <td>{\"factors\": 253, \"regularization\": 0.09613126185334961, \"iterations\": 5, \"event_weights_multiplier\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>als</td>\n",
       "      <td>0.029813</td>\n",
       "      <td>{\"factors\": 156, \"regularization\": 0.09867097597878612, \"iterations\": 12, \"event_weights_multiplier\": 44}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>als</td>\n",
       "      <td>0.029593</td>\n",
       "      <td>{\"factors\": 336, \"regularization\": 0.0026128262314916166, \"iterations\": 20, \"event_weights_multiplier\": 497}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>als</td>\n",
       "      <td>0.029473</td>\n",
       "      <td>{\"factors\": 213, \"regularization\": 0.03926240913146035, \"iterations\": 19, \"event_weights_multiplier\": 230}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>als</td>\n",
       "      <td>0.029440</td>\n",
       "      <td>{\"factors\": 233, \"regularization\": 0.04828884661481365, \"iterations\": 17, \"event_weights_multiplier\": 245}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>als</td>\n",
       "      <td>0.029407</td>\n",
       "      <td>{\"factors\": 504, \"regularization\": 0.013427555569281005, \"iterations\": 20, \"event_weights_multiplier\": 336}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>als</td>\n",
       "      <td>0.029340</td>\n",
       "      <td>{\"factors\": 505, \"regularization\": 0.0038484595207566507, \"iterations\": 20, \"event_weights_multiplier\": 453}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>als</td>\n",
       "      <td>0.029270</td>\n",
       "      <td>{\"factors\": 129, \"regularization\": 0.0010578775526821462, \"iterations\": 19, \"event_weights_multiplier\": 87}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>als</td>\n",
       "      <td>0.029253</td>\n",
       "      <td>{\"factors\": 376, \"regularization\": 0.09762147303486342, \"iterations\": 19, \"event_weights_multiplier\": 203}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>als</td>\n",
       "      <td>0.029253</td>\n",
       "      <td>{\"factors\": 137, \"regularization\": 0.09699579567545134, \"iterations\": 19, \"event_weights_multiplier\": 165}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>als</td>\n",
       "      <td>0.029243</td>\n",
       "      <td>{\"factors\": 453, \"regularization\": 0.0015619746599359369, \"iterations\": 17, \"event_weights_multiplier\": 499}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>als</td>\n",
       "      <td>0.029223</td>\n",
       "      <td>{\"factors\": 130, \"regularization\": 0.018653763171279966, \"iterations\": 12, \"event_weights_multiplier\": 141}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>als</td>\n",
       "      <td>0.029110</td>\n",
       "      <td>{\"factors\": 510, \"regularization\": 0.0020277971379165207, \"iterations\": 13, \"event_weights_multiplier\": 400}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>als</td>\n",
       "      <td>0.029087</td>\n",
       "      <td>{\"factors\": 490, \"regularization\": 0.002036497469577876, \"iterations\": 6, \"event_weights_multiplier\": 175}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>als</td>\n",
       "      <td>0.028840</td>\n",
       "      <td>{\"factors\": 136, \"regularization\": 0.003737717572600944, \"iterations\": 6, \"event_weights_multiplier\": 173}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>als</td>\n",
       "      <td>0.028810</td>\n",
       "      <td>{\"factors\": 129, \"regularization\": 0.0012015145350038068, \"iterations\": 5, \"event_weights_multiplier\": 95}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>als</td>\n",
       "      <td>0.028757</td>\n",
       "      <td>{\"factors\": 135, \"regularization\": 0.004623430882977494, \"iterations\": 13, \"event_weights_multiplier\": 236}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>als</td>\n",
       "      <td>0.028707</td>\n",
       "      <td>{\"factors\": 152, \"regularization\": 0.0016725788677921386, \"iterations\": 16, \"event_weights_multiplier\": 414}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>als</td>\n",
       "      <td>0.028637</td>\n",
       "      <td>{\"factors\": 136, \"regularization\": 0.0942689323411513, \"iterations\": 5, \"event_weights_multiplier\": 107}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>als</td>\n",
       "      <td>0.028617</td>\n",
       "      <td>{\"factors\": 133, \"regularization\": 0.0035871321783137256, \"iterations\": 20, \"event_weights_multiplier\": 322}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>als</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>{\"factors\": 325, \"regularization\": 0.09778858849766489, \"iterations\": 20, \"event_weights_multiplier\": 308}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>als</td>\n",
       "      <td>0.028443</td>\n",
       "      <td>{\"factors\": 505, \"regularization\": 0.08811483677077973, \"iterations\": 5, \"event_weights_multiplier\": 87}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>als</td>\n",
       "      <td>0.028420</td>\n",
       "      <td>{\"factors\": 137, \"regularization\": 0.09506214194818942, \"iterations\": 20, \"event_weights_multiplier\": 336}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>als</td>\n",
       "      <td>0.028370</td>\n",
       "      <td>{\"factors\": 133, \"regularization\": 0.09686045395050527, \"iterations\": 11, \"event_weights_multiplier\": 221}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>als</td>\n",
       "      <td>0.028253</td>\n",
       "      <td>{\"factors\": 134, \"regularization\": 0.001911735703045378, \"iterations\": 10, \"event_weights_multiplier\": 320}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>als</td>\n",
       "      <td>0.028060</td>\n",
       "      <td>{\"factors\": 132, \"regularization\": 0.007155050494748626, \"iterations\": 20, \"event_weights_multiplier\": 480}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>als</td>\n",
       "      <td>0.027980</td>\n",
       "      <td>{\"factors\": 366, \"regularization\": 0.09539937537294443, \"iterations\": 5, \"event_weights_multiplier\": 117}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>als</td>\n",
       "      <td>0.027960</td>\n",
       "      <td>{\"factors\": 512, \"regularization\": 0.09938124176041131, \"iterations\": 20, \"event_weights_multiplier\": 286}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>als</td>\n",
       "      <td>0.027463</td>\n",
       "      <td>{\"factors\": 134, \"regularization\": 0.05567601501705269, \"iterations\": 6, \"event_weights_multiplier\": 13}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>als</td>\n",
       "      <td>0.027430</td>\n",
       "      <td>{\"factors\": 267, \"regularization\": 0.0028764700641231533, \"iterations\": 9, \"event_weights_multiplier\": 498}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>als</td>\n",
       "      <td>0.027423</td>\n",
       "      <td>{\"factors\": 283, \"regularization\": 0.003999275689830115, \"iterations\": 5, \"event_weights_multiplier\": 250}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>als</td>\n",
       "      <td>0.027340</td>\n",
       "      <td>{\"factors\": 507, \"regularization\": 0.0986728720148368, \"iterations\": 11, \"event_weights_multiplier\": 182}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>als</td>\n",
       "      <td>0.027287</td>\n",
       "      <td>{\"factors\": 310, \"regularization\": 0.0802901644459848, \"iterations\": 13, \"event_weights_multiplier\": 343}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>als</td>\n",
       "      <td>0.027233</td>\n",
       "      <td>{\"factors\": 251, \"regularization\": 0.08220735570627472, \"iterations\": 17, \"event_weights_multiplier\": 499}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>als</td>\n",
       "      <td>0.027123</td>\n",
       "      <td>{\"factors\": 356, \"regularization\": 0.08458230910952075, \"iterations\": 18, \"event_weights_multiplier\": 425}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>als</td>\n",
       "      <td>0.027120</td>\n",
       "      <td>{\"factors\": 507, \"regularization\": 0.09637493228168972, \"iterations\": 20, \"event_weights_multiplier\": 382}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>als</td>\n",
       "      <td>0.026927</td>\n",
       "      <td>{\"factors\": 499, \"regularization\": 0.0015067861138606444, \"iterations\": 6, \"event_weights_multiplier\": 323}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>als</td>\n",
       "      <td>0.026913</td>\n",
       "      <td>{\"factors\": 130, \"regularization\": 0.09171640601253785, \"iterations\": 19, \"event_weights_multiplier\": 487}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>als</td>\n",
       "      <td>0.026750</td>\n",
       "      <td>{\"factors\": 489, \"regularization\": 0.06575014060305169, \"iterations\": 20, \"event_weights_multiplier\": 494}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>als</td>\n",
       "      <td>0.026747</td>\n",
       "      <td>{\"factors\": 131, \"regularization\": 0.09956225623980955, \"iterations\": 13, \"event_weights_multiplier\": 404}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>als</td>\n",
       "      <td>0.026657</td>\n",
       "      <td>{\"factors\": 154, \"regularization\": 0.03720688643974358, \"iterations\": 20, \"event_weights_multiplier\": 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>als</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>{\"factors\": 405, \"regularization\": 0.05861995941543562, \"iterations\": 13, \"event_weights_multiplier\": 382}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>als</td>\n",
       "      <td>0.026557</td>\n",
       "      <td>{\"factors\": 279, \"regularization\": 0.0837717975902004, \"iterations\": 10, \"event_weights_multiplier\": 328}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>als</td>\n",
       "      <td>0.026453</td>\n",
       "      <td>{\"factors\": 130, \"regularization\": 0.006827376322209294, \"iterations\": 12, \"event_weights_multiplier\": 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>als</td>\n",
       "      <td>0.026330</td>\n",
       "      <td>{\"factors\": 169, \"regularization\": 0.0478864415153191, \"iterations\": 8, \"event_weights_multiplier\": 371}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>als</td>\n",
       "      <td>0.026317</td>\n",
       "      <td>{\"factors\": 165, \"regularization\": 0.09535273368790018, \"iterations\": 14, \"event_weights_multiplier\": 465}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>als</td>\n",
       "      <td>0.026250</td>\n",
       "      <td>{\"factors\": 129, \"regularization\": 0.045919216980747975, \"iterations\": 11, \"event_weights_multiplier\": 500}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>als</td>\n",
       "      <td>0.025963</td>\n",
       "      <td>{\"factors\": 510, \"regularization\": 0.09976053231803042, \"iterations\": 13, \"event_weights_multiplier\": 340}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>als</td>\n",
       "      <td>0.025447</td>\n",
       "      <td>{\"factors\": 128, \"regularization\": 0.1, \"iterations\": 20, \"event_weights_multiplier\": 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>als</td>\n",
       "      <td>0.024927</td>\n",
       "      <td>{\"factors\": 268, \"regularization\": 0.0027131970208811177, \"iterations\": 5, \"event_weights_multiplier\": 383}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>als</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>{\"factors\": 508, \"regularization\": 0.09916809964285327, \"iterations\": 13, \"event_weights_multiplier\": 491}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>als</td>\n",
       "      <td>0.024340</td>\n",
       "      <td>{\"factors\": 130, \"regularization\": 0.08859228950974805, \"iterations\": 5, \"event_weights_multiplier\": 299}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>als</td>\n",
       "      <td>0.023657</td>\n",
       "      <td>{\"factors\": 269, \"regularization\": 0.09575836073635162, \"iterations\": 7, \"event_weights_multiplier\": 436}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>als</td>\n",
       "      <td>0.022803</td>\n",
       "      <td>{\"factors\": 459, \"regularization\": 0.09991345930413044, \"iterations\": 5, \"event_weights_multiplier\": 285}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>als</td>\n",
       "      <td>0.022527</td>\n",
       "      <td>{\"factors\": 141, \"regularization\": 0.025026583984868712, \"iterations\": 5, \"event_weights_multiplier\": 487}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>als</td>\n",
       "      <td>0.022403</td>\n",
       "      <td>{\"factors\": 481, \"regularization\": 0.004531608175778136, \"iterations\": 5, \"event_weights_multiplier\": 485}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>als</td>\n",
       "      <td>0.020947</td>\n",
       "      <td>{\"factors\": 137, \"regularization\": 0.09994822056028878, \"iterations\": 5, \"event_weights_multiplier\": 494}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>als</td>\n",
       "      <td>0.020137</td>\n",
       "      <td>{\"factors\": 504, \"regularization\": 0.09492159281990895, \"iterations\": 5, \"event_weights_multiplier\": 480}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name     score  \\\n",
       "189        als  0.031713   \n",
       "188        als  0.031677   \n",
       "199        als  0.031637   \n",
       "26         als  0.031623   \n",
       "157        als  0.031520   \n",
       "359        als  0.031493   \n",
       "5          als  0.031477   \n",
       "268        als  0.031473   \n",
       "133        als  0.031463   \n",
       "12         als  0.031433   \n",
       "398        als  0.031420   \n",
       "90         als  0.031400   \n",
       "243        als  0.031357   \n",
       "313        als  0.031333   \n",
       "316        als  0.031307   \n",
       "271        als  0.031260   \n",
       "134        als  0.031257   \n",
       "34         als  0.031220   \n",
       "346        als  0.031127   \n",
       "92         als  0.031027   \n",
       "146        als  0.031000   \n",
       "275        als  0.030980   \n",
       "310        als  0.030927   \n",
       "282        als  0.030913   \n",
       "383        als  0.030900   \n",
       "397        als  0.030787   \n",
       "368        als  0.030783   \n",
       "345        als  0.030750   \n",
       "220        als  0.030727   \n",
       "56         als  0.030720   \n",
       "153        als  0.030670   \n",
       "203        als  0.030617   \n",
       "391        als  0.030600   \n",
       "267        als  0.030437   \n",
       "340        als  0.030397   \n",
       "132        als  0.030213   \n",
       "210        als  0.030097   \n",
       "319        als  0.030047   \n",
       "165        als  0.029993   \n",
       "347        als  0.029973   \n",
       "249        als  0.029970   \n",
       "253        als  0.029907   \n",
       "29         als  0.029883   \n",
       "292        als  0.029813   \n",
       "89         als  0.029593   \n",
       "337        als  0.029473   \n",
       "306        als  0.029440   \n",
       "45         als  0.029407   \n",
       "147        als  0.029340   \n",
       "41         als  0.029270   \n",
       "293        als  0.029253   \n",
       "250        als  0.029253   \n",
       "390        als  0.029243   \n",
       "77         als  0.029223   \n",
       "207        als  0.029110   \n",
       "274        als  0.029087   \n",
       "284        als  0.028840   \n",
       "7          als  0.028810   \n",
       "63         als  0.028757   \n",
       "96         als  0.028707   \n",
       "19         als  0.028637   \n",
       "358        als  0.028617   \n",
       "178        als  0.028500   \n",
       "226        als  0.028443   \n",
       "112        als  0.028420   \n",
       "86         als  0.028370   \n",
       "6          als  0.028253   \n",
       "69         als  0.028060   \n",
       "18         als  0.027980   \n",
       "295        als  0.027960   \n",
       "367        als  0.027463   \n",
       "204        als  0.027430   \n",
       "259        als  0.027423   \n",
       "30         als  0.027340   \n",
       "342        als  0.027287   \n",
       "331        als  0.027233   \n",
       "83         als  0.027123   \n",
       "47         als  0.027120   \n",
       "82         als  0.026927   \n",
       "91         als  0.026913   \n",
       "328        als  0.026750   \n",
       "225        als  0.026747   \n",
       "60         als  0.026657   \n",
       "31         als  0.026560   \n",
       "357        als  0.026557   \n",
       "232        als  0.026453   \n",
       "235        als  0.026330   \n",
       "262        als  0.026317   \n",
       "281        als  0.026250   \n",
       "170        als  0.025963   \n",
       "377        als  0.025447   \n",
       "127        als  0.024927   \n",
       "27         als  0.024580   \n",
       "238        als  0.024340   \n",
       "4          als  0.023657   \n",
       "55         als  0.022803   \n",
       "185        als  0.022527   \n",
       "70         als  0.022403   \n",
       "76         als  0.020947   \n",
       "144        als  0.020137   \n",
       "\n",
       "                                                                                                 model_parameters  \n",
       "189                   {\"factors\": 357, \"regularization\": 0.001, \"iterations\": 20, \"event_weights_multiplier\": 63}  \n",
       "188                   {\"factors\": 339, \"regularization\": 0.001, \"iterations\": 20, \"event_weights_multiplier\": 68}  \n",
       "199    {\"factors\": 505, \"regularization\": 0.012947035211209885, \"iterations\": 19, \"event_weights_multiplier\": 33}  \n",
       "26                    {\"factors\": 438, \"regularization\": 0.001, \"iterations\": 20, \"event_weights_multiplier\": 40}  \n",
       "157                   {\"factors\": 512, \"regularization\": 0.001, \"iterations\": 20, \"event_weights_multiplier\": 24}  \n",
       "359      {\"factors\": 367, \"regularization\": 0.03905378902197729, \"iterations\": 9, \"event_weights_multiplier\": 38}  \n",
       "5                     {\"factors\": 440, \"regularization\": 0.001, \"iterations\": 18, \"event_weights_multiplier\": 37}  \n",
       "268                   {\"factors\": 366, \"regularization\": 0.001, \"iterations\": 20, \"event_weights_multiplier\": 53}  \n",
       "133                   {\"factors\": 454, \"regularization\": 0.001, \"iterations\": 20, \"event_weights_multiplier\": 46}  \n",
       "12                    {\"factors\": 423, \"regularization\": 0.001, \"iterations\": 20, \"event_weights_multiplier\": 75}  \n",
       "398                   {\"factors\": 404, \"regularization\": 0.001, \"iterations\": 20, \"event_weights_multiplier\": 88}  \n",
       "90                     {\"factors\": 359, \"regularization\": 0.001, \"iterations\": 7, \"event_weights_multiplier\": 69}  \n",
       "243    {\"factors\": 407, \"regularization\": 0.040110586464738356, \"iterations\": 20, \"event_weights_multiplier\": 54}  \n",
       "313                   {\"factors\": 341, \"regularization\": 0.001, \"iterations\": 18, \"event_weights_multiplier\": 79}  \n",
       "316     {\"factors\": 512, \"regularization\": 0.04306347380625003, \"iterations\": 16, \"event_weights_multiplier\": 46}  \n",
       "271                   {\"factors\": 512, \"regularization\": 0.001, \"iterations\": 20, \"event_weights_multiplier\": 74}  \n",
       "134                   {\"factors\": 386, \"regularization\": 0.001, \"iterations\": 14, \"event_weights_multiplier\": 92}  \n",
       "34                     {\"factors\": 314, \"regularization\": 0.001, \"iterations\": 9, \"event_weights_multiplier\": 88}  \n",
       "346                   {\"factors\": 512, \"regularization\": 0.001, \"iterations\": 16, \"event_weights_multiplier\": 77}  \n",
       "92       {\"factors\": 507, \"regularization\": 0.09215769067255868, \"iterations\": 5, \"event_weights_multiplier\": 13}  \n",
       "146     {\"factors\": 350, \"regularization\": 0.09541667165691277, \"iterations\": 16, \"event_weights_multiplier\": 18}  \n",
       "275    {\"factors\": 309, \"regularization\": 0.09781390365598827, \"iterations\": 20, \"event_weights_multiplier\": 102}  \n",
       "310    {\"factors\": 211, \"regularization\": 0.014386599167139757, \"iterations\": 10, \"event_weights_multiplier\": 83}  \n",
       "282      {\"factors\": 512, \"regularization\": 0.03294001338708355, \"iterations\": 5, \"event_weights_multiplier\": 10}  \n",
       "383                    {\"factors\": 512, \"regularization\": 0.001, \"iterations\": 8, \"event_weights_multiplier\": 70}  \n",
       "397                   {\"factors\": 512, \"regularization\": 0.001, \"iterations\": 11, \"event_weights_multiplier\": 10}  \n",
       "368                     {\"factors\": 512, \"regularization\": 0.1, \"iterations\": 12, \"event_weights_multiplier\": 10}  \n",
       "345                      {\"factors\": 399, \"regularization\": 0.1, \"iterations\": 8, \"event_weights_multiplier\": 10}  \n",
       "220     {\"factors\": 314, \"regularization\": 0.09168190060071142, \"iterations\": 20, \"event_weights_multiplier\": 18}  \n",
       "56      {\"factors\": 322, \"regularization\": 0.05571258804806584, \"iterations\": 13, \"event_weights_multiplier\": 89}  \n",
       "153     {\"factors\": 512, \"regularization\": 0.06307260070812636, \"iterations\": 20, \"event_weights_multiplier\": 10}  \n",
       "203   {\"factors\": 268, \"regularization\": 0.002217635176534642, \"iterations\": 20, \"event_weights_multiplier\": 168}  \n",
       "391                  {\"factors\": 512, \"regularization\": 0.001, \"iterations\": 20, \"event_weights_multiplier\": 183}  \n",
       "267   {\"factors\": 347, \"regularization\": 0.002495442175096357, \"iterations\": 11, \"event_weights_multiplier\": 189}  \n",
       "340     {\"factors\": 503, \"regularization\": 0.09908839492644471, \"iterations\": 19, \"event_weights_multiplier\": 97}  \n",
       "132                   {\"factors\": 327, \"regularization\": 0.001, \"iterations\": 12, \"event_weights_multiplier\": 10}  \n",
       "210  {\"factors\": 417, \"regularization\": 0.0064907955372548055, \"iterations\": 20, \"event_weights_multiplier\": 265}  \n",
       "319   {\"factors\": 276, \"regularization\": 0.003882720285079686, \"iterations\": 20, \"event_weights_multiplier\": 356}  \n",
       "165  {\"factors\": 497, \"regularization\": 0.0023673500229865977, \"iterations\": 14, \"event_weights_multiplier\": 233}  \n",
       "347    {\"factors\": 227, \"regularization\": 0.09990075038326883, \"iterations\": 14, \"event_weights_multiplier\": 150}  \n",
       "249  {\"factors\": 340, \"regularization\": 0.0010287944513174545, \"iterations\": 13, \"event_weights_multiplier\": 315}  \n",
       "253                    {\"factors\": 273, \"regularization\": 0.001, \"iterations\": 5, \"event_weights_multiplier\": 10}  \n",
       "29       {\"factors\": 253, \"regularization\": 0.09613126185334961, \"iterations\": 5, \"event_weights_multiplier\": 11}  \n",
       "292     {\"factors\": 156, \"regularization\": 0.09867097597878612, \"iterations\": 12, \"event_weights_multiplier\": 44}  \n",
       "89   {\"factors\": 336, \"regularization\": 0.0026128262314916166, \"iterations\": 20, \"event_weights_multiplier\": 497}  \n",
       "337    {\"factors\": 213, \"regularization\": 0.03926240913146035, \"iterations\": 19, \"event_weights_multiplier\": 230}  \n",
       "306    {\"factors\": 233, \"regularization\": 0.04828884661481365, \"iterations\": 17, \"event_weights_multiplier\": 245}  \n",
       "45    {\"factors\": 504, \"regularization\": 0.013427555569281005, \"iterations\": 20, \"event_weights_multiplier\": 336}  \n",
       "147  {\"factors\": 505, \"regularization\": 0.0038484595207566507, \"iterations\": 20, \"event_weights_multiplier\": 453}  \n",
       "41    {\"factors\": 129, \"regularization\": 0.0010578775526821462, \"iterations\": 19, \"event_weights_multiplier\": 87}  \n",
       "293    {\"factors\": 376, \"regularization\": 0.09762147303486342, \"iterations\": 19, \"event_weights_multiplier\": 203}  \n",
       "250    {\"factors\": 137, \"regularization\": 0.09699579567545134, \"iterations\": 19, \"event_weights_multiplier\": 165}  \n",
       "390  {\"factors\": 453, \"regularization\": 0.0015619746599359369, \"iterations\": 17, \"event_weights_multiplier\": 499}  \n",
       "77    {\"factors\": 130, \"regularization\": 0.018653763171279966, \"iterations\": 12, \"event_weights_multiplier\": 141}  \n",
       "207  {\"factors\": 510, \"regularization\": 0.0020277971379165207, \"iterations\": 13, \"event_weights_multiplier\": 400}  \n",
       "274    {\"factors\": 490, \"regularization\": 0.002036497469577876, \"iterations\": 6, \"event_weights_multiplier\": 175}  \n",
       "284    {\"factors\": 136, \"regularization\": 0.003737717572600944, \"iterations\": 6, \"event_weights_multiplier\": 173}  \n",
       "7      {\"factors\": 129, \"regularization\": 0.0012015145350038068, \"iterations\": 5, \"event_weights_multiplier\": 95}  \n",
       "63    {\"factors\": 135, \"regularization\": 0.004623430882977494, \"iterations\": 13, \"event_weights_multiplier\": 236}  \n",
       "96   {\"factors\": 152, \"regularization\": 0.0016725788677921386, \"iterations\": 16, \"event_weights_multiplier\": 414}  \n",
       "19       {\"factors\": 136, \"regularization\": 0.0942689323411513, \"iterations\": 5, \"event_weights_multiplier\": 107}  \n",
       "358  {\"factors\": 133, \"regularization\": 0.0035871321783137256, \"iterations\": 20, \"event_weights_multiplier\": 322}  \n",
       "178    {\"factors\": 325, \"regularization\": 0.09778858849766489, \"iterations\": 20, \"event_weights_multiplier\": 308}  \n",
       "226      {\"factors\": 505, \"regularization\": 0.08811483677077973, \"iterations\": 5, \"event_weights_multiplier\": 87}  \n",
       "112    {\"factors\": 137, \"regularization\": 0.09506214194818942, \"iterations\": 20, \"event_weights_multiplier\": 336}  \n",
       "86     {\"factors\": 133, \"regularization\": 0.09686045395050527, \"iterations\": 11, \"event_weights_multiplier\": 221}  \n",
       "6     {\"factors\": 134, \"regularization\": 0.001911735703045378, \"iterations\": 10, \"event_weights_multiplier\": 320}  \n",
       "69    {\"factors\": 132, \"regularization\": 0.007155050494748626, \"iterations\": 20, \"event_weights_multiplier\": 480}  \n",
       "18      {\"factors\": 366, \"regularization\": 0.09539937537294443, \"iterations\": 5, \"event_weights_multiplier\": 117}  \n",
       "295    {\"factors\": 512, \"regularization\": 0.09938124176041131, \"iterations\": 20, \"event_weights_multiplier\": 286}  \n",
       "367      {\"factors\": 134, \"regularization\": 0.05567601501705269, \"iterations\": 6, \"event_weights_multiplier\": 13}  \n",
       "204   {\"factors\": 267, \"regularization\": 0.0028764700641231533, \"iterations\": 9, \"event_weights_multiplier\": 498}  \n",
       "259    {\"factors\": 283, \"regularization\": 0.003999275689830115, \"iterations\": 5, \"event_weights_multiplier\": 250}  \n",
       "30      {\"factors\": 507, \"regularization\": 0.0986728720148368, \"iterations\": 11, \"event_weights_multiplier\": 182}  \n",
       "342     {\"factors\": 310, \"regularization\": 0.0802901644459848, \"iterations\": 13, \"event_weights_multiplier\": 343}  \n",
       "331    {\"factors\": 251, \"regularization\": 0.08220735570627472, \"iterations\": 17, \"event_weights_multiplier\": 499}  \n",
       "83     {\"factors\": 356, \"regularization\": 0.08458230910952075, \"iterations\": 18, \"event_weights_multiplier\": 425}  \n",
       "47     {\"factors\": 507, \"regularization\": 0.09637493228168972, \"iterations\": 20, \"event_weights_multiplier\": 382}  \n",
       "82    {\"factors\": 499, \"regularization\": 0.0015067861138606444, \"iterations\": 6, \"event_weights_multiplier\": 323}  \n",
       "91     {\"factors\": 130, \"regularization\": 0.09171640601253785, \"iterations\": 19, \"event_weights_multiplier\": 487}  \n",
       "328    {\"factors\": 489, \"regularization\": 0.06575014060305169, \"iterations\": 20, \"event_weights_multiplier\": 494}  \n",
       "225    {\"factors\": 131, \"regularization\": 0.09956225623980955, \"iterations\": 13, \"event_weights_multiplier\": 404}  \n",
       "60      {\"factors\": 154, \"regularization\": 0.03720688643974358, \"iterations\": 20, \"event_weights_multiplier\": 10}  \n",
       "31     {\"factors\": 405, \"regularization\": 0.05861995941543562, \"iterations\": 13, \"event_weights_multiplier\": 382}  \n",
       "357     {\"factors\": 279, \"regularization\": 0.0837717975902004, \"iterations\": 10, \"event_weights_multiplier\": 328}  \n",
       "232    {\"factors\": 130, \"regularization\": 0.006827376322209294, \"iterations\": 12, \"event_weights_multiplier\": 12}  \n",
       "235      {\"factors\": 169, \"regularization\": 0.0478864415153191, \"iterations\": 8, \"event_weights_multiplier\": 371}  \n",
       "262    {\"factors\": 165, \"regularization\": 0.09535273368790018, \"iterations\": 14, \"event_weights_multiplier\": 465}  \n",
       "281   {\"factors\": 129, \"regularization\": 0.045919216980747975, \"iterations\": 11, \"event_weights_multiplier\": 500}  \n",
       "170    {\"factors\": 510, \"regularization\": 0.09976053231803042, \"iterations\": 13, \"event_weights_multiplier\": 340}  \n",
       "377                     {\"factors\": 128, \"regularization\": 0.1, \"iterations\": 20, \"event_weights_multiplier\": 10}  \n",
       "127   {\"factors\": 268, \"regularization\": 0.0027131970208811177, \"iterations\": 5, \"event_weights_multiplier\": 383}  \n",
       "27     {\"factors\": 508, \"regularization\": 0.09916809964285327, \"iterations\": 13, \"event_weights_multiplier\": 491}  \n",
       "238     {\"factors\": 130, \"regularization\": 0.08859228950974805, \"iterations\": 5, \"event_weights_multiplier\": 299}  \n",
       "4       {\"factors\": 269, \"regularization\": 0.09575836073635162, \"iterations\": 7, \"event_weights_multiplier\": 436}  \n",
       "55      {\"factors\": 459, \"regularization\": 0.09991345930413044, \"iterations\": 5, \"event_weights_multiplier\": 285}  \n",
       "185    {\"factors\": 141, \"regularization\": 0.025026583984868712, \"iterations\": 5, \"event_weights_multiplier\": 487}  \n",
       "70     {\"factors\": 481, \"regularization\": 0.004531608175778136, \"iterations\": 5, \"event_weights_multiplier\": 485}  \n",
       "76      {\"factors\": 137, \"regularization\": 0.09994822056028878, \"iterations\": 5, \"event_weights_multiplier\": 494}  \n",
       "144     {\"factors\": 504, \"regularization\": 0.09492159281990895, \"iterations\": 5, \"event_weights_multiplier\": 480}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_model_results(\"als\", paths.tuning_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0018128929554710755, 'l1_ratio': 0.0, 'iterations': 3}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>score</th>\n",
       "      <th>model_parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.028167</td>\n",
       "      <td>{\"alpha\": 0.0018128929554710755, \"l1_ratio\": 0.0, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.027710</td>\n",
       "      <td>{\"alpha\": 0.00017683105418709883, \"l1_ratio\": 0.03668503970377813, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.027520</td>\n",
       "      <td>{\"alpha\": 7.979425322462988e-05, \"l1_ratio\": 0.007500808767095026, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.026893</td>\n",
       "      <td>{\"alpha\": 0.009724048568997815, \"l1_ratio\": 0.0001860534593675079, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.026387</td>\n",
       "      <td>{\"alpha\": 2.7414005846149176e-05, \"l1_ratio\": 0.016105149060855365, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.025877</td>\n",
       "      <td>{\"alpha\": 4.326505687923811e-05, \"l1_ratio\": 0.2938575399456759, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.025353</td>\n",
       "      <td>{\"alpha\": 6.361954945199867e-06, \"l1_ratio\": 0.17532745832264066, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.025247</td>\n",
       "      <td>{\"alpha\": 0.020410504194361453, \"l1_ratio\": 0.0002569867558397388, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.025083</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 1.0, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.025080</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.025077</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.025070</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.025067</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.025057</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.819443382725682, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.025040</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.024967</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 8.673617379884035e-19, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.024967</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.024933</td>\n",
       "      <td>{\"alpha\": 0.0005993381997203564, \"l1_ratio\": 0.0012086358270233524, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.024923</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.024920</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.024917</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.024917</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.024913</td>\n",
       "      <td>{\"alpha\": 2.7423337544929546e-05, \"l1_ratio\": 0.4797693993093475, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.024783</td>\n",
       "      <td>{\"alpha\": 7.512758982017867e-05, \"l1_ratio\": 0.004958171422844938, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.024757</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.024750</td>\n",
       "      <td>{\"alpha\": 0.00544237036264146, \"l1_ratio\": 0.0027789450935210573, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.024643</td>\n",
       "      <td>{\"alpha\": 0.0003956231953189727, \"l1_ratio\": 0.012074388549950802, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.024410</td>\n",
       "      <td>{\"alpha\": 0.00010034810204258007, \"l1_ratio\": 0.02393912196169202, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>{\"alpha\": 5.698668526545882e-05, \"l1_ratio\": 0.02220110781681384, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.024140</td>\n",
       "      <td>{\"alpha\": 0.022037622784014083, \"l1_ratio\": 0.0006423263165394878, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.023567</td>\n",
       "      <td>{\"alpha\": 0.003957314906558144, \"l1_ratio\": 0.0, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.023303</td>\n",
       "      <td>{\"alpha\": 0.004053786417674339, \"l1_ratio\": 0.0, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.022880</td>\n",
       "      <td>{\"alpha\": 1.1512954168679815e-06, \"l1_ratio\": 0.7614831504532383, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.022520</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 1.0, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.022487</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.022463</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.022453</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.022397</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.022327</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.022323</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.8574968018951977, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.022277</td>\n",
       "      <td>{\"alpha\": 0, \"l1_ratio\": 0, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.022273</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.022143</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.022137</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.022130</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.022073</td>\n",
       "      <td>{\"alpha\": 0.011790906537213411, \"l1_ratio\": 0.002185219831064123, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.022013</td>\n",
       "      <td>{\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.021943</td>\n",
       "      <td>{\"alpha\": 0.08499026405936799, \"l1_ratio\": 5.559103535046629e-05, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.021040</td>\n",
       "      <td>{\"alpha\": 2.2841147664298683e-05, \"l1_ratio\": 0.9745518412529377, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.020987</td>\n",
       "      <td>{\"alpha\": 0.009907560335334402, \"l1_ratio\": 0.0017830675793557575, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.020080</td>\n",
       "      <td>{\"alpha\": 0.018626173527032622, \"l1_ratio\": 0.0017970543400923637, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.019793</td>\n",
       "      <td>{\"alpha\": 0.02355102307507719, \"l1_ratio\": 0.0015203276496897904, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.017890</td>\n",
       "      <td>{\"alpha\": 0.020402199157049602, \"l1_ratio\": 0.0023521806406224814, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.017850</td>\n",
       "      <td>{\"alpha\": 0.09996359773066721, \"l1_ratio\": 0.0004729413907365033, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.016747</td>\n",
       "      <td>{\"alpha\": 0.01063313438198025, \"l1_ratio\": 0.004933312470018048, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.015063</td>\n",
       "      <td>{\"alpha\": 6.43292840885712e-05, \"l1_ratio\": 0.9742140716222538, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.015017</td>\n",
       "      <td>{\"alpha\": 0.050656259412934994, \"l1_ratio\": 0.001079605343005441, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.013683</td>\n",
       "      <td>{\"alpha\": 0.00013071503344028738, \"l1_ratio\": 0.46087697098750713, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.010847</td>\n",
       "      <td>{\"alpha\": 8.327899955633547e-05, \"l1_ratio\": 0.9495434010777843, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.008557</td>\n",
       "      <td>{\"alpha\": 0.022544277006919897, \"l1_ratio\": 0.005451225327286703, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.007910</td>\n",
       "      <td>{\"alpha\": 0.00010906673056061414, \"l1_ratio\": 0.973632950222227, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.007347</td>\n",
       "      <td>{\"alpha\": 0.00013016999435447877, \"l1_ratio\": 0.994412515364605, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.004713</td>\n",
       "      <td>{\"alpha\": 0.09980006905732691, \"l1_ratio\": 0.001769890299263666, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>{\"alpha\": 0.04827520396403301, \"l1_ratio\": 0.004260183981757538, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>{\"alpha\": 0.0016833551005456734, \"l1_ratio\": 0.1524110673539079, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>{\"alpha\": 0.00030097643967585974, \"l1_ratio\": 0.9987312572699779, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>{\"alpha\": 0.03980196376449483, \"l1_ratio\": 0.007369593608525517, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>{\"alpha\": 0.07151875742802109, \"l1_ratio\": 0.0041598530809501275, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>{\"alpha\": 0.08950264978020978, \"l1_ratio\": 0.00401139191906208, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>{\"alpha\": 0.09988076985071108, \"l1_ratio\": 0.004958374861855353, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>{\"alpha\": 0.019303759151650498, \"l1_ratio\": 0.031205184838480567, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>{\"alpha\": 0.0006231730927992787, \"l1_ratio\": 0.9712957813792951, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.014035078041264519, \"l1_ratio\": 0.8700872583584366, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.03927847961008299, \"l1_ratio\": 0.8360787635373778, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.09996170044123875, \"l1_ratio\": 0.7682974956639385, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.08472517387841257, \"l1_ratio\": 0.6235636967859725, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.09993405271038878, \"l1_ratio\": 0.9803800386546004, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.09991694675828627, \"l1_ratio\": 0.03929009046394561, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.06481718720511974, \"l1_ratio\": 0.368241539840548, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.027524966538148617, \"l1_ratio\": 0.9982237129822014, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.00847316581847586, \"l1_ratio\": 0.9801694026331607, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.059799627961072827, \"l1_ratio\": 0.05854702860479867, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.07586156243223574, \"l1_ratio\": 0.10590760718779216, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.053232900126843265, \"l1_ratio\": 0.9989027091509262, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.02656043820649629, \"l1_ratio\": 0.9941788563357769, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.0792191072571397, \"l1_ratio\": 0.9997802133288402, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.047766511732135, \"l1_ratio\": 0.8121687287754934, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.05928446182250185, \"l1_ratio\": 0.8442657485810175, \"iterations\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.09972688162591838, \"l1_ratio\": 0.9920929390928354, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.1, \"l1_ratio\": 1.0, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.09999001590516504, \"l1_ratio\": 0.05427728335185557, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.07206326547259169, \"l1_ratio\": 0.5820197920751072, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.09064005813546823, \"l1_ratio\": 0.9990361758674334, \"iterations\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.08009107519796445, \"l1_ratio\": 0.5204774795512049, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>slim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{\"alpha\": 0.029753460654447235, \"l1_ratio\": 0.056712977317443194, \"iterations\": 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name     score  \\\n",
       "3         slim  0.028167   \n",
       "266       slim  0.027710   \n",
       "98        slim  0.027520   \n",
       "84        slim  0.026893   \n",
       "373       slim  0.026387   \n",
       "24        slim  0.025877   \n",
       "264       slim  0.025353   \n",
       "44        slim  0.025300   \n",
       "269       slim  0.025247   \n",
       "258       slim  0.025083   \n",
       "353       slim  0.025080   \n",
       "338       slim  0.025077   \n",
       "335       slim  0.025070   \n",
       "110       slim  0.025067   \n",
       "205       slim  0.025057   \n",
       "228       slim  0.025040   \n",
       "221       slim  0.025023   \n",
       "35        slim  0.025023   \n",
       "385       slim  0.024967   \n",
       "163       slim  0.024967   \n",
       "308       slim  0.024933   \n",
       "209       slim  0.024923   \n",
       "344       slim  0.024920   \n",
       "48        slim  0.024917   \n",
       "190       slim  0.024917   \n",
       "114       slim  0.024913   \n",
       "174       slim  0.024900   \n",
       "341       slim  0.024783   \n",
       "330       slim  0.024757   \n",
       "179       slim  0.024750   \n",
       "151       slim  0.024643   \n",
       "387       slim  0.024410   \n",
       "46        slim  0.024390   \n",
       "302       slim  0.024140   \n",
       "93        slim  0.023567   \n",
       "156       slim  0.023303   \n",
       "334       slim  0.022880   \n",
       "17        slim  0.022520   \n",
       "58        slim  0.022500   \n",
       "273       slim  0.022487   \n",
       "200       slim  0.022463   \n",
       "122       slim  0.022453   \n",
       "329       slim  0.022397   \n",
       "107       slim  0.022327   \n",
       "233       slim  0.022323   \n",
       "219       slim  0.022277   \n",
       "227       slim  0.022273   \n",
       "167       slim  0.022143   \n",
       "307       slim  0.022137   \n",
       "109       slim  0.022130   \n",
       "241       slim  0.022073   \n",
       "138       slim  0.022013   \n",
       "288       slim  0.021943   \n",
       "131       slim  0.021040   \n",
       "305       slim  0.020987   \n",
       "25        slim  0.020080   \n",
       "321       slim  0.019793   \n",
       "255       slim  0.017890   \n",
       "141       slim  0.017850   \n",
       "300       slim  0.016747   \n",
       "125       slim  0.015063   \n",
       "297       slim  0.015017   \n",
       "370       slim  0.013683   \n",
       "108       slim  0.010847   \n",
       "61        slim  0.008557   \n",
       "315       slim  0.007910   \n",
       "154       slim  0.007347   \n",
       "145       slim  0.004713   \n",
       "2         slim  0.002820   \n",
       "173       slim  0.002130   \n",
       "186       slim  0.001333   \n",
       "303       slim  0.001307   \n",
       "236       slim  0.001210   \n",
       "54        slim  0.000790   \n",
       "136       slim  0.000477   \n",
       "257       slim  0.000183   \n",
       "360       slim  0.000180   \n",
       "240       slim  0.000000   \n",
       "32        slim  0.000000   \n",
       "169       slim  0.000000   \n",
       "191       slim  0.000000   \n",
       "9         slim  0.000000   \n",
       "148       slim  0.000000   \n",
       "88        slim  0.000000   \n",
       "324       slim  0.000000   \n",
       "201       slim  0.000000   \n",
       "323       slim  0.000000   \n",
       "301       slim  0.000000   \n",
       "39        slim  0.000000   \n",
       "139       slim  0.000000   \n",
       "121       slim  0.000000   \n",
       "299       slim  0.000000   \n",
       "290       slim  0.000000   \n",
       "283       slim  0.000000   \n",
       "276       slim  0.000000   \n",
       "129       slim  0.000000   \n",
       "261       slim  0.000000   \n",
       "217       slim  0.000000   \n",
       "123       slim  0.000000   \n",
       "183       slim  0.000000   \n",
       "\n",
       "                                                                         model_parameters  \n",
       "3                      {\"alpha\": 0.0018128929554710755, \"l1_ratio\": 0.0, \"iterations\": 3}  \n",
       "266   {\"alpha\": 0.00017683105418709883, \"l1_ratio\": 0.03668503970377813, \"iterations\": 3}  \n",
       "98    {\"alpha\": 7.979425322462988e-05, \"l1_ratio\": 0.007500808767095026, \"iterations\": 2}  \n",
       "84    {\"alpha\": 0.009724048568997815, \"l1_ratio\": 0.0001860534593675079, \"iterations\": 3}  \n",
       "373  {\"alpha\": 2.7414005846149176e-05, \"l1_ratio\": 0.016105149060855365, \"iterations\": 2}  \n",
       "24      {\"alpha\": 4.326505687923811e-05, \"l1_ratio\": 0.2938575399456759, \"iterations\": 3}  \n",
       "264    {\"alpha\": 6.361954945199867e-06, \"l1_ratio\": 0.17532745832264066, \"iterations\": 2}  \n",
       "44                                       {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}  \n",
       "269   {\"alpha\": 0.020410504194361453, \"l1_ratio\": 0.0002569867558397388, \"iterations\": 2}  \n",
       "258                                      {\"alpha\": 0.0, \"l1_ratio\": 1.0, \"iterations\": 3}  \n",
       "353                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}  \n",
       "338                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}  \n",
       "335                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}  \n",
       "110                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}  \n",
       "205                        {\"alpha\": 0.0, \"l1_ratio\": 0.819443382725682, \"iterations\": 3}  \n",
       "228                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}  \n",
       "221                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}  \n",
       "35                                       {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}  \n",
       "385                    {\"alpha\": 0.0, \"l1_ratio\": 8.673617379884035e-19, \"iterations\": 3}  \n",
       "163                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}  \n",
       "308  {\"alpha\": 0.0005993381997203564, \"l1_ratio\": 0.0012086358270233524, \"iterations\": 1}  \n",
       "209                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}  \n",
       "344                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}  \n",
       "48                                       {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}  \n",
       "190                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}  \n",
       "114    {\"alpha\": 2.7423337544929546e-05, \"l1_ratio\": 0.4797693993093475, \"iterations\": 2}  \n",
       "174                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}  \n",
       "341   {\"alpha\": 7.512758982017867e-05, \"l1_ratio\": 0.004958171422844938, \"iterations\": 1}  \n",
       "330                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 3}  \n",
       "179    {\"alpha\": 0.00544237036264146, \"l1_ratio\": 0.0027789450935210573, \"iterations\": 3}  \n",
       "151   {\"alpha\": 0.0003956231953189727, \"l1_ratio\": 0.012074388549950802, \"iterations\": 1}  \n",
       "387   {\"alpha\": 0.00010034810204258007, \"l1_ratio\": 0.02393912196169202, \"iterations\": 1}  \n",
       "46     {\"alpha\": 5.698668526545882e-05, \"l1_ratio\": 0.02220110781681384, \"iterations\": 1}  \n",
       "302   {\"alpha\": 0.022037622784014083, \"l1_ratio\": 0.0006423263165394878, \"iterations\": 2}  \n",
       "93                      {\"alpha\": 0.003957314906558144, \"l1_ratio\": 0.0, \"iterations\": 1}  \n",
       "156                     {\"alpha\": 0.004053786417674339, \"l1_ratio\": 0.0, \"iterations\": 1}  \n",
       "334    {\"alpha\": 1.1512954168679815e-06, \"l1_ratio\": 0.7614831504532383, \"iterations\": 1}  \n",
       "17                                       {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}  \n",
       "58                                       {\"alpha\": 0.0, \"l1_ratio\": 1.0, \"iterations\": 1}  \n",
       "273                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}  \n",
       "200                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}  \n",
       "122                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}  \n",
       "329                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}  \n",
       "107                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}  \n",
       "233                       {\"alpha\": 0.0, \"l1_ratio\": 0.8574968018951977, \"iterations\": 1}  \n",
       "219                                          {\"alpha\": 0, \"l1_ratio\": 0, \"iterations\": 1}  \n",
       "227                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}  \n",
       "167                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}  \n",
       "307                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}  \n",
       "109                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}  \n",
       "241    {\"alpha\": 0.011790906537213411, \"l1_ratio\": 0.002185219831064123, \"iterations\": 2}  \n",
       "138                                      {\"alpha\": 0.0, \"l1_ratio\": 0.0, \"iterations\": 1}  \n",
       "288    {\"alpha\": 0.08499026405936799, \"l1_ratio\": 5.559103535046629e-05, \"iterations\": 1}  \n",
       "131    {\"alpha\": 2.2841147664298683e-05, \"l1_ratio\": 0.9745518412529377, \"iterations\": 1}  \n",
       "305   {\"alpha\": 0.009907560335334402, \"l1_ratio\": 0.0017830675793557575, \"iterations\": 1}  \n",
       "25    {\"alpha\": 0.018626173527032622, \"l1_ratio\": 0.0017970543400923637, \"iterations\": 2}  \n",
       "321    {\"alpha\": 0.02355102307507719, \"l1_ratio\": 0.0015203276496897904, \"iterations\": 2}  \n",
       "255   {\"alpha\": 0.020402199157049602, \"l1_ratio\": 0.0023521806406224814, \"iterations\": 2}  \n",
       "141    {\"alpha\": 0.09996359773066721, \"l1_ratio\": 0.0004729413907365033, \"iterations\": 2}  \n",
       "300     {\"alpha\": 0.01063313438198025, \"l1_ratio\": 0.004933312470018048, \"iterations\": 2}  \n",
       "125      {\"alpha\": 6.43292840885712e-05, \"l1_ratio\": 0.9742140716222538, \"iterations\": 2}  \n",
       "297    {\"alpha\": 0.050656259412934994, \"l1_ratio\": 0.001079605343005441, \"iterations\": 1}  \n",
       "370   {\"alpha\": 0.00013071503344028738, \"l1_ratio\": 0.46087697098750713, \"iterations\": 1}  \n",
       "108     {\"alpha\": 8.327899955633547e-05, \"l1_ratio\": 0.9495434010777843, \"iterations\": 1}  \n",
       "61     {\"alpha\": 0.022544277006919897, \"l1_ratio\": 0.005451225327286703, \"iterations\": 3}  \n",
       "315     {\"alpha\": 0.00010906673056061414, \"l1_ratio\": 0.973632950222227, \"iterations\": 1}  \n",
       "154     {\"alpha\": 0.00013016999435447877, \"l1_ratio\": 0.994412515364605, \"iterations\": 2}  \n",
       "145     {\"alpha\": 0.09980006905732691, \"l1_ratio\": 0.001769890299263666, \"iterations\": 2}  \n",
       "2       {\"alpha\": 0.04827520396403301, \"l1_ratio\": 0.004260183981757538, \"iterations\": 1}  \n",
       "173     {\"alpha\": 0.0016833551005456734, \"l1_ratio\": 0.1524110673539079, \"iterations\": 3}  \n",
       "186    {\"alpha\": 0.00030097643967585974, \"l1_ratio\": 0.9987312572699779, \"iterations\": 3}  \n",
       "303     {\"alpha\": 0.03980196376449483, \"l1_ratio\": 0.007369593608525517, \"iterations\": 1}  \n",
       "236    {\"alpha\": 0.07151875742802109, \"l1_ratio\": 0.0041598530809501275, \"iterations\": 2}  \n",
       "54       {\"alpha\": 0.08950264978020978, \"l1_ratio\": 0.00401139191906208, \"iterations\": 2}  \n",
       "136     {\"alpha\": 0.09988076985071108, \"l1_ratio\": 0.004958374861855353, \"iterations\": 2}  \n",
       "257    {\"alpha\": 0.019303759151650498, \"l1_ratio\": 0.031205184838480567, \"iterations\": 3}  \n",
       "360     {\"alpha\": 0.0006231730927992787, \"l1_ratio\": 0.9712957813792951, \"iterations\": 3}  \n",
       "240      {\"alpha\": 0.014035078041264519, \"l1_ratio\": 0.8700872583584366, \"iterations\": 2}  \n",
       "32        {\"alpha\": 0.03927847961008299, \"l1_ratio\": 0.8360787635373778, \"iterations\": 2}  \n",
       "169       {\"alpha\": 0.09996170044123875, \"l1_ratio\": 0.7682974956639385, \"iterations\": 3}  \n",
       "191       {\"alpha\": 0.08472517387841257, \"l1_ratio\": 0.6235636967859725, \"iterations\": 2}  \n",
       "9         {\"alpha\": 0.09993405271038878, \"l1_ratio\": 0.9803800386546004, \"iterations\": 2}  \n",
       "148      {\"alpha\": 0.09991694675828627, \"l1_ratio\": 0.03929009046394561, \"iterations\": 3}  \n",
       "88         {\"alpha\": 0.06481718720511974, \"l1_ratio\": 0.368241539840548, \"iterations\": 3}  \n",
       "324      {\"alpha\": 0.027524966538148617, \"l1_ratio\": 0.9982237129822014, \"iterations\": 3}  \n",
       "201       {\"alpha\": 0.00847316581847586, \"l1_ratio\": 0.9801694026331607, \"iterations\": 1}  \n",
       "323     {\"alpha\": 0.059799627961072827, \"l1_ratio\": 0.05854702860479867, \"iterations\": 1}  \n",
       "301      {\"alpha\": 0.07586156243223574, \"l1_ratio\": 0.10590760718779216, \"iterations\": 2}  \n",
       "39       {\"alpha\": 0.053232900126843265, \"l1_ratio\": 0.9989027091509262, \"iterations\": 3}  \n",
       "139       {\"alpha\": 0.02656043820649629, \"l1_ratio\": 0.9941788563357769, \"iterations\": 2}  \n",
       "121        {\"alpha\": 0.0792191072571397, \"l1_ratio\": 0.9997802133288402, \"iterations\": 2}  \n",
       "299         {\"alpha\": 0.047766511732135, \"l1_ratio\": 0.8121687287754934, \"iterations\": 2}  \n",
       "290       {\"alpha\": 0.05928446182250185, \"l1_ratio\": 0.8442657485810175, \"iterations\": 3}  \n",
       "283       {\"alpha\": 0.09972688162591838, \"l1_ratio\": 0.9920929390928354, \"iterations\": 1}  \n",
       "276                                      {\"alpha\": 0.1, \"l1_ratio\": 1.0, \"iterations\": 1}  \n",
       "129      {\"alpha\": 0.09999001590516504, \"l1_ratio\": 0.05427728335185557, \"iterations\": 1}  \n",
       "261       {\"alpha\": 0.07206326547259169, \"l1_ratio\": 0.5820197920751072, \"iterations\": 2}  \n",
       "217       {\"alpha\": 0.09064005813546823, \"l1_ratio\": 0.9990361758674334, \"iterations\": 1}  \n",
       "123       {\"alpha\": 0.08009107519796445, \"l1_ratio\": 0.5204774795512049, \"iterations\": 2}  \n",
       "183    {\"alpha\": 0.029753460654447235, \"l1_ratio\": 0.056712977317443194, \"iterations\": 2}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_model_results(\"slim\", paths.tuning_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no_components': 512,\n",
       " 'k': 3,\n",
       " 'n': 20,\n",
       " 'learning_schedule': 'adadelta',\n",
       " 'loss': 'warp',\n",
       " 'max_sampled': 61,\n",
       " 'epochs': 11}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>score</th>\n",
       "      <th>model_parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024950</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 3, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 61, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024940</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 3, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 61, \"epochs\": 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024923</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 3, \"n\": 18, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 77, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024913</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 10, \"n\": 7, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 73, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024850</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 9, \"n\": 1, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 84, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024767</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 3, \"n\": 18, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 77, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024757</td>\n",
       "      <td>{\"no_components\": 508, \"k\": 2, \"n\": 5, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024737</td>\n",
       "      <td>{\"no_components\": 461, \"k\": 1, \"n\": 12, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 27, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024690</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 1, \"n\": 18, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 75, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024687</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 10, \"n\": 1, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 79, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024610</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 4, \"n\": 7, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024603</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 5, \"n\": 7, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024603</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 2, \"n\": 7, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 2, \"n\": 14, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>{\"no_components\": 313, \"k\": 2, \"n\": 10, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024597</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 1, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 15, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024590</td>\n",
       "      <td>{\"no_components\": 511, \"k\": 2, \"n\": 5, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024570</td>\n",
       "      <td>{\"no_components\": 416, \"k\": 8, \"n\": 19, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024483</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 9, \"n\": 9, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 40, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024473</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 8, \"n\": 15, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 31, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 1, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 44, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024237</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 1, \"n\": 10, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 45, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024233</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 6, \"n\": 2, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024027</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 7, \"n\": 19, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 51, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.024007</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 1, \"n\": 8, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 61, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.023957</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 8, \"n\": 2, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 53, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.023877</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 2, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 13}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>{\"no_components\": 296, \"k\": 1, \"n\": 10, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 14}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.023633</td>\n",
       "      <td>{\"no_components\": 400, \"k\": 10, \"n\": 14, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 68, \"epochs\": 19}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.023570</td>\n",
       "      <td>{\"no_components\": 509, \"k\": 1, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 87, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.023563</td>\n",
       "      <td>{\"no_components\": 217, \"k\": 3, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 64, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.023320</td>\n",
       "      <td>{\"no_components\": 269, \"k\": 2, \"n\": 1, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 100, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.023213</td>\n",
       "      <td>{\"no_components\": 338, \"k\": 9, \"n\": 8, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 1, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.023153</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 3, \"n\": 18, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 82, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.022907</td>\n",
       "      <td>{\"no_components\": 433, \"k\": 6, \"n\": 12, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 67, \"epochs\": 16}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.022747</td>\n",
       "      <td>{\"no_components\": 340, \"k\": 5, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.022677</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 1, \"n\": 18, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 6, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.022637</td>\n",
       "      <td>{\"no_components\": 507, \"k\": 8, \"n\": 7, \"learning_schedule\": \"adadelta\", \"loss\": \"warp-kos\", \"max_sampled\": 27, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.022613</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 3, \"n\": 7, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 43, \"epochs\": 16}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>{\"no_components\": 84, \"k\": 8, \"n\": 16, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 54, \"epochs\": 19}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.021597</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 3, \"n\": 17, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 35, \"epochs\": 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.021130</td>\n",
       "      <td>{\"no_components\": 172, \"k\": 1, \"n\": 13, \"learning_schedule\": \"adagrad\", \"loss\": \"warp\", \"max_sampled\": 64, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.020860</td>\n",
       "      <td>{\"no_components\": 307, \"k\": 9, \"n\": 17, \"learning_schedule\": \"adagrad\", \"loss\": \"warp\", \"max_sampled\": 39, \"epochs\": 7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.020587</td>\n",
       "      <td>{\"no_components\": 384, \"k\": 1, \"n\": 19, \"learning_schedule\": \"adagrad\", \"loss\": \"warp\", \"max_sampled\": 72, \"epochs\": 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.020543</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 4, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 100, \"epochs\": 7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.020493</td>\n",
       "      <td>{\"no_components\": 313, \"k\": 2, \"n\": 12, \"learning_schedule\": \"adagrad\", \"loss\": \"warp\", \"max_sampled\": 32, \"epochs\": 7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.020477</td>\n",
       "      <td>{\"no_components\": 490, \"k\": 1, \"n\": 20, \"learning_schedule\": \"adagrad\", \"loss\": \"warp\", \"max_sampled\": 75, \"epochs\": 6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.020123</td>\n",
       "      <td>{\"no_components\": 508, \"k\": 2, \"n\": 3, \"learning_schedule\": \"adagrad\", \"loss\": \"warp-kos\", \"max_sampled\": 97, \"epochs\": 9}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.020063</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 6, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 1, \"epochs\": 19}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.020043</td>\n",
       "      <td>{\"no_components\": 430, \"k\": 9, \"n\": 20, \"learning_schedule\": \"adagrad\", \"loss\": \"warp\", \"max_sampled\": 42, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.019993</td>\n",
       "      <td>{\"no_components\": 412, \"k\": 6, \"n\": 14, \"learning_schedule\": \"adagrad\", \"loss\": \"warp\", \"max_sampled\": 54, \"epochs\": 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.019857</td>\n",
       "      <td>{\"no_components\": 53, \"k\": 6, \"n\": 7, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 27, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.019693</td>\n",
       "      <td>{\"no_components\": 26, \"k\": 3, \"n\": 3, \"learning_schedule\": \"adagrad\", \"loss\": \"warp\", \"max_sampled\": 92, \"epochs\": 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.019397</td>\n",
       "      <td>{\"no_components\": 254, \"k\": 2, \"n\": 19, \"learning_schedule\": \"adagrad\", \"loss\": \"bpr\", \"max_sampled\": 100, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.019257</td>\n",
       "      <td>{\"no_components\": 502, \"k\": 5, \"n\": 13, \"learning_schedule\": \"adagrad\", \"loss\": \"warp-kos\", \"max_sampled\": 45, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.019230</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 4, \"n\": 18, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 30, \"epochs\": 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.019173</td>\n",
       "      <td>{\"no_components\": 78, \"k\": 4, \"n\": 14, \"learning_schedule\": \"adadelta\", \"loss\": \"warp-kos\", \"max_sampled\": 70, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.018737</td>\n",
       "      <td>{\"no_components\": 496, \"k\": 3, \"n\": 4, \"learning_schedule\": \"adagrad\", \"loss\": \"warp-kos\", \"max_sampled\": 94, \"epochs\": 16}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.018733</td>\n",
       "      <td>{\"no_components\": 503, \"k\": 1, \"n\": 11, \"learning_schedule\": \"adadelta\", \"loss\": \"warp-kos\", \"max_sampled\": 54, \"epochs\": 14}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.017190</td>\n",
       "      <td>{\"no_components\": 454, \"k\": 2, \"n\": 14, \"learning_schedule\": \"adagrad\", \"loss\": \"bpr\", \"max_sampled\": 3, \"epochs\": 17}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.017170</td>\n",
       "      <td>{\"no_components\": 340, \"k\": 1, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp-kos\", \"max_sampled\": 100, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>{\"no_components\": 173, \"k\": 2, \"n\": 18, \"learning_schedule\": \"adagrad\", \"loss\": \"warp-kos\", \"max_sampled\": 93, \"epochs\": 14}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>{\"no_components\": 371, \"k\": 10, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp-kos\", \"max_sampled\": 1, \"epochs\": 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.016033</td>\n",
       "      <td>{\"no_components\": 18, \"k\": 10, \"n\": 2, \"learning_schedule\": \"adagrad\", \"loss\": \"bpr\", \"max_sampled\": 4, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.015983</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 2, \"n\": 11, \"learning_schedule\": \"adagrad\", \"loss\": \"warp-kos\", \"max_sampled\": 11, \"epochs\": 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.015523</td>\n",
       "      <td>{\"no_components\": 68, \"k\": 6, \"n\": 12, \"learning_schedule\": \"adadelta\", \"loss\": \"warp-kos\", \"max_sampled\": 4, \"epochs\": 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.014083</td>\n",
       "      <td>{\"no_components\": 505, \"k\": 4, \"n\": 9, \"learning_schedule\": \"adagrad\", \"loss\": \"bpr\", \"max_sampled\": 99, \"epochs\": 14}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>{\"no_components\": 19, \"k\": 2, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 49, \"epochs\": 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.012983</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 5, \"n\": 10, \"learning_schedule\": \"adagrad\", \"loss\": \"warp-kos\", \"max_sampled\": 1, \"epochs\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.012090</td>\n",
       "      <td>{\"no_components\": 8, \"k\": 6, \"n\": 7, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.011183</td>\n",
       "      <td>{\"no_components\": 73, \"k\": 1, \"n\": 10, \"learning_schedule\": \"adagrad\", \"loss\": \"warp-kos\", \"max_sampled\": 47, \"epochs\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.011023</td>\n",
       "      <td>{\"no_components\": 11, \"k\": 6, \"n\": 14, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 99, \"epochs\": 16}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.010777</td>\n",
       "      <td>{\"no_components\": 11, \"k\": 6, \"n\": 3, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 3, \"epochs\": 14}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.009637</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 7, \"n\": 20, \"learning_schedule\": \"adagrad\", \"loss\": \"warp\", \"max_sampled\": 92, \"epochs\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.009463</td>\n",
       "      <td>{\"no_components\": 447, \"k\": 4, \"n\": 7, \"learning_schedule\": \"adadelta\", \"loss\": \"warp-kos\", \"max_sampled\": 58, \"epochs\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>{\"no_components\": 178, \"k\": 7, \"n\": 8, \"learning_schedule\": \"adagrad\", \"loss\": \"bpr\", \"max_sampled\": 87, \"epochs\": 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 1, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 33, \"epochs\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>{\"no_components\": 21, \"k\": 9, \"n\": 18, \"learning_schedule\": \"adadelta\", \"loss\": \"warp-kos\", \"max_sampled\": 99, \"epochs\": 7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.006943</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 2, \"n\": 4, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 4, \"epochs\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.006510</td>\n",
       "      <td>{\"no_components\": 58, \"k\": 10, \"n\": 13, \"learning_schedule\": \"adadelta\", \"loss\": \"logistic\", \"max_sampled\": 75, \"epochs\": 13}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.005760</td>\n",
       "      <td>{\"no_components\": 9, \"k\": 3, \"n\": 14, \"learning_schedule\": \"adagrad\", \"loss\": \"warp-kos\", \"max_sampled\": 7, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.004767</td>\n",
       "      <td>{\"no_components\": 8, \"k\": 1, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 1, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 5, \"n\": 16, \"learning_schedule\": \"adadelta\", \"loss\": \"logistic\", \"max_sampled\": 32, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.004650</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 9, \"n\": 1, \"learning_schedule\": \"adadelta\", \"loss\": \"logistic\", \"max_sampled\": 21, \"epochs\": 18}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.004550</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 7, \"n\": 6, \"learning_schedule\": \"adadelta\", \"loss\": \"logistic\", \"max_sampled\": 100, \"epochs\": 17}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 10, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"logistic\", \"max_sampled\": 71, \"epochs\": 14}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>{\"no_components\": 53, \"k\": 2, \"n\": 16, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 92, \"epochs\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>{\"no_components\": 502, \"k\": 3, \"n\": 1, \"learning_schedule\": \"adadelta\", \"loss\": \"logistic\", \"max_sampled\": 40, \"epochs\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>{\"no_components\": 8, \"k\": 4, \"n\": 3, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>{\"no_components\": 8, \"k\": 8, \"n\": 13, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>{\"no_components\": 8, \"k\": 8, \"n\": 15, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 1, \"epochs\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>{\"no_components\": 8, \"k\": 5, \"n\": 11, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>{\"no_components\": 37, \"k\": 6, \"n\": 14, \"learning_schedule\": \"adagrad\", \"loss\": \"logistic\", \"max_sampled\": 99, \"epochs\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>{\"no_components\": 369, \"k\": 1, \"n\": 15, \"learning_schedule\": \"adagrad\", \"loss\": \"logistic\", \"max_sampled\": 74, \"epochs\": 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>{\"no_components\": 83, \"k\": 3, \"n\": 8, \"learning_schedule\": \"adagrad\", \"loss\": \"logistic\", \"max_sampled\": 62, \"epochs\": 18}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>{\"no_components\": 301, \"k\": 5, \"n\": 10, \"learning_schedule\": \"adagrad\", \"loss\": \"logistic\", \"max_sampled\": 68, \"epochs\": 7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>{\"no_components\": 37, \"k\": 3, \"n\": 10, \"learning_schedule\": \"adagrad\", \"loss\": \"logistic\", \"max_sampled\": 40, \"epochs\": 17}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>{\"no_components\": 61, \"k\": 5, \"n\": 5, \"learning_schedule\": \"adagrad\", \"loss\": \"logistic\", \"max_sampled\": 14, \"epochs\": 7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>{\"no_components\": 8, \"k\": 10, \"n\": 15, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 1, \"epochs\": 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>lightfm</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>{\"no_components\": 512, \"k\": 4, \"n\": 2, \"learning_schedule\": \"adagrad\", \"loss\": \"bpr\", \"max_sampled\": 1, \"epochs\": 7}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name     score  \\\n",
       "400    lightfm  0.024950   \n",
       "401    lightfm  0.024940   \n",
       "402    lightfm  0.024923   \n",
       "403    lightfm  0.024913   \n",
       "404    lightfm  0.024850   \n",
       "405    lightfm  0.024767   \n",
       "406    lightfm  0.024757   \n",
       "407    lightfm  0.024737   \n",
       "408    lightfm  0.024690   \n",
       "409    lightfm  0.024687   \n",
       "410    lightfm  0.024610   \n",
       "411    lightfm  0.024603   \n",
       "412    lightfm  0.024603   \n",
       "413    lightfm  0.024600   \n",
       "414    lightfm  0.024600   \n",
       "415    lightfm  0.024597   \n",
       "416    lightfm  0.024590   \n",
       "417    lightfm  0.024570   \n",
       "418    lightfm  0.024483   \n",
       "419    lightfm  0.024473   \n",
       "420    lightfm  0.024390   \n",
       "421    lightfm  0.024237   \n",
       "422    lightfm  0.024233   \n",
       "423    lightfm  0.024027   \n",
       "424    lightfm  0.024007   \n",
       "425    lightfm  0.023957   \n",
       "426    lightfm  0.023877   \n",
       "427    lightfm  0.023700   \n",
       "428    lightfm  0.023633   \n",
       "429    lightfm  0.023570   \n",
       "430    lightfm  0.023563   \n",
       "431    lightfm  0.023320   \n",
       "432    lightfm  0.023213   \n",
       "433    lightfm  0.023153   \n",
       "434    lightfm  0.022907   \n",
       "435    lightfm  0.022747   \n",
       "436    lightfm  0.022677   \n",
       "437    lightfm  0.022637   \n",
       "438    lightfm  0.022613   \n",
       "439    lightfm  0.021653   \n",
       "440    lightfm  0.021597   \n",
       "441    lightfm  0.021130   \n",
       "442    lightfm  0.020860   \n",
       "443    lightfm  0.020587   \n",
       "444    lightfm  0.020543   \n",
       "445    lightfm  0.020493   \n",
       "446    lightfm  0.020477   \n",
       "447    lightfm  0.020123   \n",
       "448    lightfm  0.020063   \n",
       "449    lightfm  0.020043   \n",
       "450    lightfm  0.019993   \n",
       "451    lightfm  0.019857   \n",
       "452    lightfm  0.019693   \n",
       "453    lightfm  0.019397   \n",
       "454    lightfm  0.019257   \n",
       "455    lightfm  0.019230   \n",
       "456    lightfm  0.019173   \n",
       "457    lightfm  0.018737   \n",
       "458    lightfm  0.018733   \n",
       "459    lightfm  0.017190   \n",
       "460    lightfm  0.017170   \n",
       "461    lightfm  0.016393   \n",
       "462    lightfm  0.016100   \n",
       "463    lightfm  0.016033   \n",
       "464    lightfm  0.015983   \n",
       "465    lightfm  0.015523   \n",
       "466    lightfm  0.014083   \n",
       "467    lightfm  0.013400   \n",
       "468    lightfm  0.012983   \n",
       "469    lightfm  0.012090   \n",
       "470    lightfm  0.011183   \n",
       "471    lightfm  0.011023   \n",
       "472    lightfm  0.010777   \n",
       "473    lightfm  0.009637   \n",
       "474    lightfm  0.009463   \n",
       "475    lightfm  0.009177   \n",
       "476    lightfm  0.007943   \n",
       "477    lightfm  0.007463   \n",
       "478    lightfm  0.006943   \n",
       "479    lightfm  0.006510   \n",
       "480    lightfm  0.005760   \n",
       "481    lightfm  0.004767   \n",
       "482    lightfm  0.004740   \n",
       "483    lightfm  0.004650   \n",
       "484    lightfm  0.004550   \n",
       "485    lightfm  0.004520   \n",
       "486    lightfm  0.003013   \n",
       "487    lightfm  0.002677   \n",
       "488    lightfm  0.002593   \n",
       "489    lightfm  0.001760   \n",
       "490    lightfm  0.001680   \n",
       "491    lightfm  0.001673   \n",
       "492    lightfm  0.001670   \n",
       "493    lightfm  0.001667   \n",
       "495    lightfm  0.001663   \n",
       "496    lightfm  0.001663   \n",
       "497    lightfm  0.001663   \n",
       "494    lightfm  0.001663   \n",
       "498    lightfm  0.001630   \n",
       "499    lightfm  0.001410   \n",
       "\n",
       "                                                                                                                   model_parameters  \n",
       "400       {\"no_components\": 512, \"k\": 3, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 61, \"epochs\": 11}  \n",
       "401       {\"no_components\": 512, \"k\": 3, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 61, \"epochs\": 10}  \n",
       "402       {\"no_components\": 512, \"k\": 3, \"n\": 18, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 77, \"epochs\": 11}  \n",
       "403       {\"no_components\": 512, \"k\": 10, \"n\": 7, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 73, \"epochs\": 11}  \n",
       "404        {\"no_components\": 512, \"k\": 9, \"n\": 1, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 84, \"epochs\": 11}  \n",
       "405       {\"no_components\": 512, \"k\": 3, \"n\": 18, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 77, \"epochs\": 11}  \n",
       "406       {\"no_components\": 508, \"k\": 2, \"n\": 5, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 11}  \n",
       "407       {\"no_components\": 461, \"k\": 1, \"n\": 12, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 27, \"epochs\": 20}  \n",
       "408       {\"no_components\": 512, \"k\": 1, \"n\": 18, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 75, \"epochs\": 11}  \n",
       "409       {\"no_components\": 512, \"k\": 10, \"n\": 1, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 79, \"epochs\": 11}  \n",
       "410       {\"no_components\": 512, \"k\": 4, \"n\": 7, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 11}  \n",
       "411       {\"no_components\": 512, \"k\": 5, \"n\": 7, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 11}  \n",
       "412       {\"no_components\": 512, \"k\": 2, \"n\": 7, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 11}  \n",
       "413      {\"no_components\": 512, \"k\": 2, \"n\": 14, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 11}  \n",
       "414      {\"no_components\": 313, \"k\": 2, \"n\": 10, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 11}  \n",
       "415       {\"no_components\": 512, \"k\": 1, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 15, \"epochs\": 20}  \n",
       "416       {\"no_components\": 511, \"k\": 2, \"n\": 5, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 11}  \n",
       "417      {\"no_components\": 416, \"k\": 8, \"n\": 19, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 11}  \n",
       "418        {\"no_components\": 512, \"k\": 9, \"n\": 9, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 40, \"epochs\": 20}  \n",
       "419       {\"no_components\": 512, \"k\": 8, \"n\": 15, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 31, \"epochs\": 20}  \n",
       "420       {\"no_components\": 512, \"k\": 1, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 44, \"epochs\": 20}  \n",
       "421       {\"no_components\": 512, \"k\": 1, \"n\": 10, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 45, \"epochs\": 20}  \n",
       "422       {\"no_components\": 512, \"k\": 6, \"n\": 2, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 11}  \n",
       "423       {\"no_components\": 512, \"k\": 7, \"n\": 19, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 51, \"epochs\": 20}  \n",
       "424        {\"no_components\": 512, \"k\": 1, \"n\": 8, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 61, \"epochs\": 20}  \n",
       "425        {\"no_components\": 512, \"k\": 8, \"n\": 2, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 53, \"epochs\": 20}  \n",
       "426      {\"no_components\": 512, \"k\": 2, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 13}  \n",
       "427      {\"no_components\": 296, \"k\": 1, \"n\": 10, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 14}  \n",
       "428      {\"no_components\": 400, \"k\": 10, \"n\": 14, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 68, \"epochs\": 19}  \n",
       "429       {\"no_components\": 509, \"k\": 1, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 87, \"epochs\": 20}  \n",
       "430       {\"no_components\": 217, \"k\": 3, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 64, \"epochs\": 20}  \n",
       "431        {\"no_components\": 269, \"k\": 2, \"n\": 1, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 100, \"epochs\": 20}  \n",
       "432          {\"no_components\": 338, \"k\": 9, \"n\": 8, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 1, \"epochs\": 20}  \n",
       "433        {\"no_components\": 512, \"k\": 3, \"n\": 18, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 82, \"epochs\": 20}  \n",
       "434        {\"no_components\": 433, \"k\": 6, \"n\": 12, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 67, \"epochs\": 16}  \n",
       "435      {\"no_components\": 340, \"k\": 5, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 20}  \n",
       "436        {\"no_components\": 512, \"k\": 1, \"n\": 18, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 6, \"epochs\": 11}  \n",
       "437    {\"no_components\": 507, \"k\": 8, \"n\": 7, \"learning_schedule\": \"adadelta\", \"loss\": \"warp-kos\", \"max_sampled\": 27, \"epochs\": 20}  \n",
       "438         {\"no_components\": 512, \"k\": 3, \"n\": 7, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 43, \"epochs\": 16}  \n",
       "439         {\"no_components\": 84, \"k\": 8, \"n\": 16, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 54, \"epochs\": 19}  \n",
       "440        {\"no_components\": 512, \"k\": 3, \"n\": 17, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 35, \"epochs\": 10}  \n",
       "441        {\"no_components\": 172, \"k\": 1, \"n\": 13, \"learning_schedule\": \"adagrad\", \"loss\": \"warp\", \"max_sampled\": 64, \"epochs\": 20}  \n",
       "442         {\"no_components\": 307, \"k\": 9, \"n\": 17, \"learning_schedule\": \"adagrad\", \"loss\": \"warp\", \"max_sampled\": 39, \"epochs\": 7}  \n",
       "443        {\"no_components\": 384, \"k\": 1, \"n\": 19, \"learning_schedule\": \"adagrad\", \"loss\": \"warp\", \"max_sampled\": 72, \"epochs\": 10}  \n",
       "444        {\"no_components\": 512, \"k\": 4, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 100, \"epochs\": 7}  \n",
       "445         {\"no_components\": 313, \"k\": 2, \"n\": 12, \"learning_schedule\": \"adagrad\", \"loss\": \"warp\", \"max_sampled\": 32, \"epochs\": 7}  \n",
       "446         {\"no_components\": 490, \"k\": 1, \"n\": 20, \"learning_schedule\": \"adagrad\", \"loss\": \"warp\", \"max_sampled\": 75, \"epochs\": 6}  \n",
       "447      {\"no_components\": 508, \"k\": 2, \"n\": 3, \"learning_schedule\": \"adagrad\", \"loss\": \"warp-kos\", \"max_sampled\": 97, \"epochs\": 9}  \n",
       "448        {\"no_components\": 512, \"k\": 6, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 1, \"epochs\": 19}  \n",
       "449        {\"no_components\": 430, \"k\": 9, \"n\": 20, \"learning_schedule\": \"adagrad\", \"loss\": \"warp\", \"max_sampled\": 42, \"epochs\": 20}  \n",
       "450        {\"no_components\": 412, \"k\": 6, \"n\": 14, \"learning_schedule\": \"adagrad\", \"loss\": \"warp\", \"max_sampled\": 54, \"epochs\": 15}  \n",
       "451         {\"no_components\": 53, \"k\": 6, \"n\": 7, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 27, \"epochs\": 11}  \n",
       "452          {\"no_components\": 26, \"k\": 3, \"n\": 3, \"learning_schedule\": \"adagrad\", \"loss\": \"warp\", \"max_sampled\": 92, \"epochs\": 12}  \n",
       "453        {\"no_components\": 254, \"k\": 2, \"n\": 19, \"learning_schedule\": \"adagrad\", \"loss\": \"bpr\", \"max_sampled\": 100, \"epochs\": 20}  \n",
       "454    {\"no_components\": 502, \"k\": 5, \"n\": 13, \"learning_schedule\": \"adagrad\", \"loss\": \"warp-kos\", \"max_sampled\": 45, \"epochs\": 20}  \n",
       "455         {\"no_components\": 512, \"k\": 4, \"n\": 18, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 30, \"epochs\": 5}  \n",
       "456    {\"no_components\": 78, \"k\": 4, \"n\": 14, \"learning_schedule\": \"adadelta\", \"loss\": \"warp-kos\", \"max_sampled\": 70, \"epochs\": 20}  \n",
       "457     {\"no_components\": 496, \"k\": 3, \"n\": 4, \"learning_schedule\": \"adagrad\", \"loss\": \"warp-kos\", \"max_sampled\": 94, \"epochs\": 16}  \n",
       "458   {\"no_components\": 503, \"k\": 1, \"n\": 11, \"learning_schedule\": \"adadelta\", \"loss\": \"warp-kos\", \"max_sampled\": 54, \"epochs\": 14}  \n",
       "459          {\"no_components\": 454, \"k\": 2, \"n\": 14, \"learning_schedule\": \"adagrad\", \"loss\": \"bpr\", \"max_sampled\": 3, \"epochs\": 17}  \n",
       "460  {\"no_components\": 340, \"k\": 1, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp-kos\", \"max_sampled\": 100, \"epochs\": 20}  \n",
       "461    {\"no_components\": 173, \"k\": 2, \"n\": 18, \"learning_schedule\": \"adagrad\", \"loss\": \"warp-kos\", \"max_sampled\": 93, \"epochs\": 14}  \n",
       "462   {\"no_components\": 371, \"k\": 10, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp-kos\", \"max_sampled\": 1, \"epochs\": 11}  \n",
       "463           {\"no_components\": 18, \"k\": 10, \"n\": 2, \"learning_schedule\": \"adagrad\", \"loss\": \"bpr\", \"max_sampled\": 4, \"epochs\": 20}  \n",
       "464    {\"no_components\": 512, \"k\": 2, \"n\": 11, \"learning_schedule\": \"adagrad\", \"loss\": \"warp-kos\", \"max_sampled\": 11, \"epochs\": 10}  \n",
       "465     {\"no_components\": 68, \"k\": 6, \"n\": 12, \"learning_schedule\": \"adadelta\", \"loss\": \"warp-kos\", \"max_sampled\": 4, \"epochs\": 15}  \n",
       "466          {\"no_components\": 505, \"k\": 4, \"n\": 9, \"learning_schedule\": \"adagrad\", \"loss\": \"bpr\", \"max_sampled\": 99, \"epochs\": 14}  \n",
       "467         {\"no_components\": 19, \"k\": 2, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 49, \"epochs\": 10}  \n",
       "468      {\"no_components\": 512, \"k\": 5, \"n\": 10, \"learning_schedule\": \"adagrad\", \"loss\": \"warp-kos\", \"max_sampled\": 1, \"epochs\": 3}  \n",
       "469         {\"no_components\": 8, \"k\": 6, \"n\": 7, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 20}  \n",
       "470      {\"no_components\": 73, \"k\": 1, \"n\": 10, \"learning_schedule\": \"adagrad\", \"loss\": \"warp-kos\", \"max_sampled\": 47, \"epochs\": 3}  \n",
       "471         {\"no_components\": 11, \"k\": 6, \"n\": 14, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 99, \"epochs\": 16}  \n",
       "472           {\"no_components\": 11, \"k\": 6, \"n\": 3, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 3, \"epochs\": 14}  \n",
       "473         {\"no_components\": 512, \"k\": 7, \"n\": 20, \"learning_schedule\": \"adagrad\", \"loss\": \"warp\", \"max_sampled\": 92, \"epochs\": 1}  \n",
       "474     {\"no_components\": 447, \"k\": 4, \"n\": 7, \"learning_schedule\": \"adadelta\", \"loss\": \"warp-kos\", \"max_sampled\": 58, \"epochs\": 1}  \n",
       "475          {\"no_components\": 178, \"k\": 7, \"n\": 8, \"learning_schedule\": \"adagrad\", \"loss\": \"bpr\", \"max_sampled\": 87, \"epochs\": 10}  \n",
       "476        {\"no_components\": 512, \"k\": 1, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 33, \"epochs\": 1}  \n",
       "477     {\"no_components\": 21, \"k\": 9, \"n\": 18, \"learning_schedule\": \"adadelta\", \"loss\": \"warp-kos\", \"max_sampled\": 99, \"epochs\": 7}  \n",
       "478           {\"no_components\": 512, \"k\": 2, \"n\": 4, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 4, \"epochs\": 1}  \n",
       "479   {\"no_components\": 58, \"k\": 10, \"n\": 13, \"learning_schedule\": \"adadelta\", \"loss\": \"logistic\", \"max_sampled\": 75, \"epochs\": 13}  \n",
       "480       {\"no_components\": 9, \"k\": 3, \"n\": 14, \"learning_schedule\": \"adagrad\", \"loss\": \"warp-kos\", \"max_sampled\": 7, \"epochs\": 20}  \n",
       "481          {\"no_components\": 8, \"k\": 1, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 1, \"epochs\": 20}  \n",
       "482   {\"no_components\": 512, \"k\": 5, \"n\": 16, \"learning_schedule\": \"adadelta\", \"loss\": \"logistic\", \"max_sampled\": 32, \"epochs\": 20}  \n",
       "483    {\"no_components\": 512, \"k\": 9, \"n\": 1, \"learning_schedule\": \"adadelta\", \"loss\": \"logistic\", \"max_sampled\": 21, \"epochs\": 18}  \n",
       "484   {\"no_components\": 512, \"k\": 7, \"n\": 6, \"learning_schedule\": \"adadelta\", \"loss\": \"logistic\", \"max_sampled\": 100, \"epochs\": 17}  \n",
       "485  {\"no_components\": 512, \"k\": 10, \"n\": 20, \"learning_schedule\": \"adadelta\", \"loss\": \"logistic\", \"max_sampled\": 71, \"epochs\": 14}  \n",
       "486          {\"no_components\": 53, \"k\": 2, \"n\": 16, \"learning_schedule\": \"adadelta\", \"loss\": \"bpr\", \"max_sampled\": 92, \"epochs\": 1}  \n",
       "487     {\"no_components\": 502, \"k\": 3, \"n\": 1, \"learning_schedule\": \"adadelta\", \"loss\": \"logistic\", \"max_sampled\": 40, \"epochs\": 1}  \n",
       "488          {\"no_components\": 8, \"k\": 4, \"n\": 3, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 3}  \n",
       "489         {\"no_components\": 8, \"k\": 8, \"n\": 13, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 1}  \n",
       "490           {\"no_components\": 8, \"k\": 8, \"n\": 15, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 1, \"epochs\": 1}  \n",
       "491         {\"no_components\": 8, \"k\": 5, \"n\": 11, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 100, \"epochs\": 1}  \n",
       "492      {\"no_components\": 37, \"k\": 6, \"n\": 14, \"learning_schedule\": \"adagrad\", \"loss\": \"logistic\", \"max_sampled\": 99, \"epochs\": 1}  \n",
       "493    {\"no_components\": 369, \"k\": 1, \"n\": 15, \"learning_schedule\": \"adagrad\", \"loss\": \"logistic\", \"max_sampled\": 74, \"epochs\": 20}  \n",
       "495      {\"no_components\": 83, \"k\": 3, \"n\": 8, \"learning_schedule\": \"adagrad\", \"loss\": \"logistic\", \"max_sampled\": 62, \"epochs\": 18}  \n",
       "496     {\"no_components\": 301, \"k\": 5, \"n\": 10, \"learning_schedule\": \"adagrad\", \"loss\": \"logistic\", \"max_sampled\": 68, \"epochs\": 7}  \n",
       "497     {\"no_components\": 37, \"k\": 3, \"n\": 10, \"learning_schedule\": \"adagrad\", \"loss\": \"logistic\", \"max_sampled\": 40, \"epochs\": 17}  \n",
       "494       {\"no_components\": 61, \"k\": 5, \"n\": 5, \"learning_schedule\": \"adagrad\", \"loss\": \"logistic\", \"max_sampled\": 14, \"epochs\": 7}  \n",
       "498          {\"no_components\": 8, \"k\": 10, \"n\": 15, \"learning_schedule\": \"adadelta\", \"loss\": \"warp\", \"max_sampled\": 1, \"epochs\": 1}  \n",
       "499            {\"no_components\": 512, \"k\": 4, \"n\": 2, \"learning_schedule\": \"adagrad\", \"loss\": \"bpr\", \"max_sampled\": 1, \"epochs\": 7}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_model_results(\"lightfm\", paths.tuning_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jobs-research",
   "language": "python",
   "name": "jobs-research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
